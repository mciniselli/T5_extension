{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "isr_HP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s_8ZTxrFEa2"
      },
      "source": [
        "### Configuration of the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h1MRzBLtex2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65d1452-ac7f-4c40-947e-121684244306"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip3 install --upgrade pip\n",
        "#!pip install -qU t5\n",
        "!pip3 install git+https://github.com/google-research/text-to-text-transfer-transformer.git #extra_id_x support\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "#Set the base dir(Google cloud bucket)\n",
        "BASE_DIR = \"gs://bucket_comment_completion\" \n",
        "\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "\n",
        "if ON_CLOUD:\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/ef/60d7ba03b5c442309ef42e7d69959f73aacccd0d86008362a681c4698e83/pip-21.0.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 6.0MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-21.0.1\n",
            "Collecting git+https://github.com/google-research/text-to-text-transfer-transformer.git\n",
            "  Cloning https://github.com/google-research/text-to-text-transfer-transformer.git to /tmp/pip-req-build-2rlzfg82\n",
            "  Running command git clone -q https://github.com/google-research/text-to-text-transfer-transformer.git /tmp/pip-req-build-2rlzfg82\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (0.10.0)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (2.9.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (0.4.0)\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "  Downloading mesh_tensorflow-0.1.18-py3-none-any.whl (361 kB)\n",
            "\u001b[K     |████████████████████████████████| 361 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (1.1.5)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (1.4.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 18.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14 in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (1.15.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.4.3-cp36-cp36m-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 37.4 MB/s \n",
            "\u001b[?25hCollecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.2.0.dev202101300107-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (1.7.0+cu101)\n",
            "Collecting transformers>=2.7.0\n",
            "  Downloading transformers-4.2.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 71.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (4.0.1)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 65.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (0.8)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (3.4.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
            "\u001b[K     |████████████████████████████████| 883 kB 71.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (20.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (4.41.1)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel->t5==0.8.1) (2018.9)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers>=2.7.0->t5==0.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers>=2.7.0->t5==0.8.1) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=2.7.0->t5==0.8.1) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->t5==0.8.1) (2.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.8.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.8.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.8.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.8.1) (2020.12.5)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.2.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.8.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.8.1) (1.0.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (2.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (20.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (0.27.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (5.1.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (1.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (0.3.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (0.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (51.3.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (1.52.0)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text->t5==0.8.1) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text->t5==0.8.1) (0.11.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.12.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.3.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (2.4.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.36.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (2.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.4.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (3.1.0)\n",
            "Building wheels for collected packages: t5, sacremoses\n",
            "  Building wheel for t5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for t5: filename=t5-0.8.1-py3-none-any.whl size=221270 sha256=5d56f70d0184a9c3674df3244b70bc3af989d2bd45caca62b4da5b9b329c8a2a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dj7yo4ik/wheels/aa/e1/a1/847d16e451940b1fe89940aa88875c96ae2f7cc63e509e9226\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893258 sha256=b3655677fbfdcbe03716b404ceccb180a49d2f1ff4441f7621068943a1c0720e\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
            "Successfully built t5 sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, portalocker, mesh-tensorflow, transformers, tfds-nightly, tensorflow-text, sentencepiece, sacrebleu, rouge-score, t5\n",
            "Successfully installed mesh-tensorflow-0.1.18 portalocker-2.2.0 rouge-score-0.0.4 sacrebleu-1.5.0 sacremoses-0.0.43 sentencepiece-0.1.95 t5-0.8.1 tensorflow-text-2.4.3 tfds-nightly-4.2.0.dev202101300107 tokenizers-0.9.4 transformers-4.2.2\n",
            "Running on TPU: grpc://10.116.164.242:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxryXo0SFTfH"
      },
      "source": [
        "### Loading of the tsv files\n",
        "We loaded the 6 tsv files, please be sure to upload them on the bucket and to copy the correct path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glLJUm1dxIiH"
      },
      "source": [
        "#Validation(train and test on the same dataset)\n",
        "\n",
        "nq_tsv_path_java_construct = {\n",
        "    \"train\":      'gs://bucket_comment_completion/Matteo/ft_datasets/train_java_construct.tsv',\n",
        "    \"validation\": 'gs://bucket_comment_completion/Matteo/ft_datasets/eval_java_construct.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples_java_construct = dict(train=750000, validation=104037)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-B3_th9eP5y"
      },
      "source": [
        "#Validation(train and test on the same dataset)\n",
        "\n",
        "nq_tsv_path_android_construct = {\n",
        "    \"train\":      'gs://bucket_comment_completion/Matteo/ft_datasets/train_android_construct.tsv',\n",
        "    \"validation\": 'gs://bucket_comment_completion/Matteo/ft_datasets/eval_android_construct.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples_android_construct = dict(train=750000, validation=98793)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u7JbyjV8GN3"
      },
      "source": [
        "#Validation(train and test on the same dataset)\n",
        "\n",
        "nq_tsv_path_java_block = {\n",
        "    \"train\":      'gs://bucket_comment_completion/Matteo/ft_datasets/train_java_block.tsv',\n",
        "    \"validation\": 'gs://bucket_comment_completion/Matteo/ft_datasets/eval_java_block.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples_java_block = dict(train=298470, validation=38840)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmUMU-Pg8HVm"
      },
      "source": [
        "#Validation(train and test on the same dataset)\n",
        "\n",
        "nq_tsv_path_android_block = {\n",
        "    \"train\":      'gs://bucket_comment_completion/Matteo/ft_datasets/train_android_block.tsv',\n",
        "    \"validation\": 'gs://bucket_comment_completion/Matteo/ft_datasets/eval_android_block.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples_android_block = dict(train=204580, validation=26503)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5lRmNWG8HuD"
      },
      "source": [
        "#Validation(train and test on the same dataset)\n",
        "\n",
        "nq_tsv_path_java_token = {\n",
        "    \"train\":      'gs://bucket_comment_completion/Matteo/ft_datasets/train_java_token.tsv',\n",
        "    \"validation\": 'gs://bucket_comment_completion/Matteo/ft_datasets/eval_java_token.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples_java_token = dict(train=750000, validation=214682)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF9DHJxc8IGe"
      },
      "source": [
        "#Validation(train and test on the same dataset)\n",
        "\n",
        "nq_tsv_path_android_token = {\n",
        "    \"train\":      'gs://bucket_comment_completion/Matteo/ft_datasets/train_android_token.tsv',\n",
        "    \"validation\": 'gs://bucket_comment_completion/Matteo/ft_datasets/eval_android_token.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples_android_token = dict(train=750000, validation=198281)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jIzuVEOFvGl"
      },
      "source": [
        "### Preprocess of the dataset\n",
        "In this step we preprocess the dataset.  \n",
        "You have to change the path to vocab files (*vocab_model_path* and *vocab_path*)\n",
        "We're going to preprocess all the tsv file so that T5 can use them for HP tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PobLvzL18zzR"
      },
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "vocab_model_path = 'gs://bucket_comment_completion/Matteo/code.model'\n",
        "vocab_path = 'gs://bucket_comment_completion/Matteo/code.vocab'\n",
        "\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn-DMH5FkSO2"
      },
      "source": [
        "JAVA CONSTRUCT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0NTLbyXvkCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dffcee2-fa30-45ac-c2c4-b051ce680aa4"
      },
      "source": [
        "def nq_java_construct(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "   # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_java_construct[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(nq_java_construct(\"train\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw train examples...\n",
            "{'input': b'public void updateLockdownExceptions(ManagedObjectReference _this, String[] users) throws AuthMinimumAdminPermission, RemoteException, RuntimeFault, UserNotFound { Argument[] params = new Argument[2]; params[0] = new Argument(\"_this\", \"ManagedObjectReference\", _this); params[1] = new Argument(\"users\", \"String[]\", users); getWsc().invoke( <extra_id_0>); }', 'output': b'\"UpdateLockdownExceptions\", params, null'}\n",
            "{'input': b'@Override public Collection<AgentProjectInfo> collectDependencies(String folder) { if ( <extra_id_0>){ devDependencies = findDevDependencies(folder); } File yarnLock = new File(folder + fileSeparator + YARN_LOCK); boolean yarnLockFound = yarnLock.isFile(); Collection<DependencyInfo> dependencies = new ArrayList<>(); if (yarnLockFound){ dependencies = parseYarnLock(yarnLock); } else { npmLsFailureStatus = true; } return getSingleProjectList(dependencies); }', 'output': b'!includeDevDependencies'}\n",
            "{'input': b'@Override public Collection<AgentProjectInfo> collectDependencies(String folder) { if (!includeDevDependencies){ devDependencies = findDevDependencies(folder); } File yarnLock = new File(folder + fileSeparator + YARN_LOCK); boolean yarnLockFound = yarnLock.isFile(); Collection<DependencyInfo> dependencies = new ArrayList<>(); if ( <extra_id_0>){ dependencies = parseYarnLock(yarnLock); } else { npmLsFailureStatus = true; } return getSingleProjectList(dependencies); }', 'output': b'yarnLockFound'}\n",
            "{'input': b'@Override public Collection<AgentProjectInfo> collectDependencies(String folder) { if (!includeDevDependencies){ devDependencies = findDevDependencies(folder); } File yarnLock = new File( <extra_id_0>); boolean yarnLockFound = yarnLock.isFile(); Collection<DependencyInfo> dependencies = new ArrayList<>(); if (yarnLockFound){ dependencies = parseYarnLock(yarnLock); } else { npmLsFailureStatus = true; } return getSingleProjectList(dependencies); }', 'output': b'folder + fileSeparator + YARN_LOCK'}\n",
            "{'input': b'@Override public Collection<AgentProjectInfo> collectDependencies(String folder) { if (!includeDevDependencies){ devDependencies = findDevDependencies(folder); } File yarnLock = new File(folder + fileSeparator + YARN_LOCK); boolean yarnLockFound = yarnLock.isFile(); Collection<DependencyInfo> dependencies = new ArrayList<>(); if (yarnLockFound){ dependencies = parseYarnLock(yarnLock); } else { npmLsFailureStatus = true; } return getSingleProjectList( <extra_id_0>); }', 'output': b'dependencies'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bJZPQgjxKZ1"
      },
      "source": [
        "def java_construct_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['JAVA_CONSTRUCT:' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3jAg8Zhx_Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73795372-0ab4-4dfd-fe2d-e734d75a0bce"
      },
      "source": [
        "t5.data.TaskRegistry.remove('java_construct')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"java_construct\",\n",
        "    dataset_fn=nq_java_construct,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[java_construct_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_java_construct\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f7881812b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e71p9JIFyYHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4badc465-7950-4755-9ef2-54c53094b4ac"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"java_construct\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 256, \"targets\": 256})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'JAVA_CONSTRUCT:private void addJavaDoc(JDocCommentable docCommentable) { JDocComment javadoc = docCommentable.javadoc(); javadoc.append( <extra_id_0>); }', 'inputs': array([    3,  7641,    15,  5071, 17558,    56,  8797,    20,   162,\n",
            "       28631,     5,   808,  1361,  1341,   367,  1009,  1341,   367,\n",
            "           8,     7,  1570,  1361,  1341,     3, 14480,    11,  1009,\n",
            "        1341,   367,     4, 14480,    18,     3, 14480,     4,   109,\n",
            "           5, 32099,    10,     6,     1], dtype=int32), 'targets_pretokenized': b'REQUIRED_COMMENT_TEXT', 'targets': array([ 7572,     2,  8424,    15, 10867,    15,   989,     2,    70,\n",
            "           1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_CONSTRUCT:@Bean public NativeEnvironmentRepository nativeEnvironmentRepository( NativeEnvironmentRepositoryFactory factory, NativeEnvironmentProperties environmentProperties) { return factory.build( <extra_id_0>); }', 'inputs': array([    3,  7641,    15,  5071, 17558,    56,  2098,   388,    12,\n",
            "        8831,  1176,   458,  3841,  1176,   458,     5,  8831,  1176,\n",
            "         458,   149,  1081,     9,  8831,  1176,   277,  2511,   277,\n",
            "           8,     7,    14,  1081,     4,   352,     5, 32099,    10,\n",
            "           6,     1], dtype=int32), 'targets_pretokenized': b'environmentProperties', 'targets': array([2511,  277,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_CONSTRUCT:private void excludeMBeanIfNecessary(Object candidate, String beanName, ApplicationContext context) { for (MBeanExporter mbeanExporter : context.getBeansOfType(MBeanExporter.class) .values()) { if (JmxUtils.isMBean( <extra_id_0>)) { mbeanExporter.addExcludedBean(beanName); } } }', 'inputs': array([    3,  7641,    15,  5071, 17558,    56,  8797,    20,  5739,\n",
            "        5940,  8571,     5,    96,  5452,     9,    26, 20334,     9,\n",
            "        2256,    92,   130,     8,     7,    50,    17,  5940,  6213,\n",
            "          54,  2167,  6213,    58,   130,     4,  5152, 19929,     5,\n",
            "        5940,  6213,     4,    88,     8,     3,     4,   457,    60,\n",
            "           7,    21,    17,  7234,   217,     4,   112,  5940,     5,\n",
            "       32099,     8,     8,     7,    54,  2167,  6213,     4,    67,\n",
            "        6617,   388,     5, 19771,    10,     6,     6,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'candidate.getClass()', 'targets': array([5452,    4,  398,   16,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_CONSTRUCT:private void doWait( int currentTries, long optDuration_ms ) { if ( optDuration_ms < 0 ) { optDuration_ms = ( long ) ( firstSleep_ms * ( Math.random() + 0.5 ) * ( 1L << ( currentTries - 1 ) ) ); } LOGGER.debug( \"Will retry request after {} millis\", optDuration_ms ); try { Thread.sleep( <extra_id_0>); } catch ( InterruptedException ex ) { throw new CStorageException( \"Retry waiting interrupted\", ex ); } }', 'inputs': array([    3,  7641,    15,  5071, 17558,    56,  8797,    20,   396,\n",
            "        3181,     5,    35,   337, 18255,     9,   126,  4562,  1440,\n",
            "          15,  2653,     3,     8,     7,    21,    17,  4562,  1440,\n",
            "          15,  2653,   136,   157,     3,     8,     7,  4562,  1440,\n",
            "          15,  2653,    11,    17,   126,     3,     8,    17,   607,\n",
            "        8128,    15,  2653,     3,     2,    17,   608,     4,  2215,\n",
            "          16,    34,  1830,     2,     3,     8,     3,     2,    17,\n",
            "         279,   215,  1477,    17,   337, 18255,   139,   279,     3,\n",
            "           8,     3,     8,     3,    10,     6,   990,     4,   407,\n",
            "           5,    32,  7395,  4799,   190,  1056,   601,  6416,    43,\n",
            "        4562,  1440,    15,  2653,     3,    10,    93,     7,  1078,\n",
            "           4,  1904,     5, 32099,    10,     6,    97,    17,  1441,\n",
            "          38,   480,     3,     8,     7,    78,    24,   810,  7145,\n",
            "           5,    32,  2843,  5977, 11270,    43,   480,     3,    10,\n",
            "           6,     6,     1], dtype=int32), 'targets_pretokenized': b'optDuration_ms', 'targets': array([4562, 1440,   15, 2653,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_CONSTRUCT:public static Connection createConnection() throws SQLException { MjdbcUtils.loadDriver(\"oracle.jdbc.pool.OracleDataSource\"); OracleDataSource ds = new oracle.jdbc.pool.OracleDataSource(); ds.setDriverType(\"thin\"); ds.setServerName(\"localhost\"); ds.setDatabaseName(\"xe\"); ds.setPortNumber(1521); ds.setUser( <extra_id_0>); ds.setPassword(\"welcome1\"); Connection conn = ds.getConnection(); return conn; }', 'inputs': array([    3,  7641,    15,  5071, 17558,    56,  4569,    48,  2097,\n",
            "           3, 14181,    16,    42,   275,     2,   520,     7,  1653,\n",
            "        5052,   217,     4,   839,  1642,    28, 12971,     4,  5052,\n",
            "           4,  3170,     4,  6935,  1852,    46,     3,  6935,  1852,\n",
            "        2533,    11,    24,     3, 12971,     4,  5052,     4,  3170,\n",
            "           4,  6935,  1852,    18,  2533,     4,    63,  1642,    51,\n",
            "          28,  1120,   321,    46,  2533,     4,    63, 19413,    28,\n",
            "        3704,    46,  2533,     4,    63,  1019,    66,    28,   138,\n",
            "         110,    46,  2533,     4,    63, 26199,     5,    94,     2,\n",
            "        2994,    10,  2533,     4,  9261,     5, 32099,    10,  2533,\n",
            "           4,  6758,    28, 19200,  4024,  2097,  1683,    11,  2533,\n",
            "           4,  2965,    18,    14,  1683,    13,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'\"chris\"', 'targets': array([   32, 12763,   112,    83,     1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB-KY403kcCn"
      },
      "source": [
        "JAVA TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNi7HPiOz27q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f27c1f-4369-477a-c67c-363d6d32485a"
      },
      "source": [
        "def nq_java_token(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_java_token[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw valid examples...\")\n",
        "for ex in tfds.as_numpy(nq_java_token(\"validation\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw valid examples...\n",
            "{'input': b'public void addThirdPartyPaymentWorkflow(com.mozu.api.contracts.sitesettings.order.ExternalPaymentWorkflowDefinition definition) throws Exception { MozuClient client = com.mozu.api.clients.commerce.settings.checkout.PaymentSettingsClient <extra_id_0> client.setContext(_apiContext); client.executeRequest(); client.cleanupHttpConnection(); }', 'output': b'.addThirdPartyPaymentWorkflowClient( definition);'}\n",
            "{'input': b'public void addThirdPartyPaymentWorkflow(com.mozu.api.contracts.sitesettings.order.ExternalPaymentWorkflowDefinition definition) throws Exception { MozuClient client = com.mozu.api.clients.commerce.settings.checkout.PaymentSettingsClient.addThirdPartyPaymentWorkflowClient( definition); client.setContext(_apiContext <extra_id_0> client.executeRequest(); client.cleanupHttpConnection(); }', 'output': b');'}\n",
            "{'input': b'public void addThirdPartyPaymentWorkflow(com.mozu.api.contracts.sitesettings.order.ExternalPaymentWorkflowDefinition definition) throws Exception { MozuClient client = com.mozu.api.clients.commerce.settings.checkout.PaymentSettingsClient.addThirdPartyPaymentWorkflowClient( definition); client.setContext(_apiContext); client <extra_id_0> client.cleanupHttpConnection(); }', 'output': b'.executeRequest();'}\n",
            "{'input': b'public void addThirdPartyPaymentWorkflow(com.mozu.api.contracts.sitesettings.order.ExternalPaymentWorkflowDefinition definition) throws Exception { MozuClient client = com.mozu.api.clients.commerce.settings.checkout.PaymentSettingsClient.addThirdPartyPaymentWorkflowClient( definition); client.setContext(_apiContext); client.executeRequest(); client.cleanupHttpConnection <extra_id_0> }', 'output': b'();'}\n",
            "{'input': b'protected Map<String, List<MigratingVariableInstance>> getMigratingVariableInstancesByName(MigratingActivityInstance activityInstance) { Map<String, List<MigratingVariableInstance>> result = new HashMap<String, List<MigratingVariableInstance <extra_id_0> for (MigratingInstance migratingInstance : activityInstance.getMigratingDependentInstances()) { if (migratingInstance instanceof MigratingVariableInstance) { MigratingVariableInstance migratingVariableInstance = (MigratingVariableInstance) migratingInstance; CollectionUtil.addToMapOfLists(result, migratingVariableInstance.getVariableName(), migratingVariableInstance); } } return result; }', 'output': b'>>();'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvDAbgNY0B4Y"
      },
      "source": [
        "def java_token_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['JAVA_TOKEN:' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mm6AQfw0INC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b545775-71d5-40af-a103-2441f1034cb4"
      },
      "source": [
        "t5.data.TaskRegistry.remove('java_token')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"java_token\",\n",
        "    dataset_fn=nq_java_token,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[java_token_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_java_token\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f7761206048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnf25qt10Wkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b647afce-fdfd-463e-e3ea-60feaff5ddf6"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"java_token\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 256, \"targets\": 256})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'inputs_pretokenized': b'JAVA_TOKEN:public T withMatcher(final String matcherName, final Matcher matcher) { this.configuration = configuration.withMatcher(matcherName, matcher); return (T) this <extra_id_0> }', 'inputs': array([    3,  7641,    15,  2591,    56,  4569,   299,   273,  1588,\n",
            "           5,    64,    26,  2116,    66,     9,    44,  2908,  2116,\n",
            "           8,     7,    23,     4,  1382,    11,   739,     4,   616,\n",
            "        1588,     5,  1311,    66,     9,  2116,    10,    14,    17,\n",
            "          70,     8,    23, 32099,     6,     1], dtype=int32), 'targets_pretokenized': b';', 'targets': array([ 3, 13,  1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_TOKEN:@Override public <extra_id_0> if (this.rendition != null) { return ModificationDate.get(this.rendition.getRendition().adaptTo(Resource.class)); } else { return null; } }', 'inputs': array([    3,  7641,    15,  2591,    56,  2098,    27,    12, 32099,\n",
            "          21,    17,    75,     4,   185,   852, 18717,    49,    30,\n",
            "           8,     7,    14,     3,  3261,   267,     4,    33,     5,\n",
            "          75,     4,   185,   852, 18717,     4,    33,   144,   852,\n",
            "       18717,    37, 25826,     5,   256,     4,    88,    79,     6,\n",
            "          77,     7,    14,    30,    13,     6,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'Date getModificationDate() {', 'targets': array([ 617,   41, 3261,  267,   16,    7,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_TOKEN:public static boolean defaultTransactionSupported(final String persistenceUnit, final KunderaMetadata kunderaMetadata) { PersistenceUnitMetadata puMetadata = KunderaMetadataManager.getPersistenceUnitMetadata(kunderaMetadata, persistenceUnit); String txResource = puMetadata.getProperty(PersistenceProperties.KUNDERA_TRANSACTION_RESOURCE); if (txResource == null) { return true; } else if (txResource.isEmpty()) { throw new IllegalArgumentException(\"Property \" + PersistenceProperties.KUNDERA_TRANSACTION_RESOURCE + \" is blank\" <extra_id_0> } else { return false; } }', 'inputs': array([    3,  7641,    15,  2591,    56,  4569,    48,    45,   289,\n",
            "         737,  2170,     5,    64,    26,     3, 25534,     9,    44,\n",
            "        2289, 13550,   184,   411,     3, 30065,   411,     8,     7,\n",
            "           3, 27457,   411, 16380,   411,    11,  2289, 13550,   184,\n",
            "         411,   121,     4,    33, 27457,   411,     5, 30065,   411,\n",
            "           9,     3, 25534,    10,    26,  3241,   256,    11, 16380,\n",
            "         411,     4,   761,     5,  2906,   277,     4,   390, 25717,\n",
            "         236,    15, 12610,    15,  4081,    10,    21,    17,  4674,\n",
            "         256,    40,    30,     8,     7,    14,    89,    13,     6,\n",
            "          77,    21,    17,  4674,   256,     4,   280,    60,     7,\n",
            "          78,    24,   381,    38,    28,   220,    32,    34,  7317,\n",
            "         277,     4,   390, 25717,   236,    15, 12610,    15,  4081,\n",
            "          34,    32,    69,  7577,    83, 32099,     6,    77,     7,\n",
            "          14,    76,    13,     6,     6,     1], dtype=int32), 'targets_pretokenized': b');', 'targets': array([ 3, 10,  1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_TOKEN:private void resolveImageDependencies(List<Resolvable> resolved) throws DockerAccessException, ResolveSteadyStateException { boolean changed = false; Iterator<Resolvable> iterator = secondPass.iterator(); while (iterator <extra_id_0> Resolvable config = iterator.next(); if (hasRequiredDependencies(config)) { updateProcessedImages(config); resolved.add(config); changed = true; iterator.remove(); } } if (!changed) { throw new ResolveSteadyStateException(); } }', 'inputs': array([    3,  7641,    15,  2591,    56,  8797,    20,  1589,   516,\n",
            "        3962,     5,    71,    25, 31600,    29,  5272,     8,    42,\n",
            "       14995,  7037,     9,     3,  4620, 23997,    38,     7,    45,\n",
            "        2126,    11,    76,    13,  1154,    25, 31600,    29,  1694,\n",
            "          11,  1959,  2829,     4,   774,    18,   317,    17,   774,\n",
            "       32099,     3, 31600,   309,    11,  1694,     4,   395,    18,\n",
            "          21,    17,   521,  1557,  3962,     5,   505,     8,     8,\n",
            "           7,   233,  5383,  3715,     5,   505,    10,  5272,     4,\n",
            "          67,     5,   505,    10,  2126,    11,    89,    13,  1694,\n",
            "           4,   252,    18,     6,     6,    21,   124,  5416,     8,\n",
            "           7,    78,    24,     3,  4620, 23997,    38,    18,     6,\n",
            "           6,     1], dtype=int32), 'targets_pretokenized': b'.hasNext()) {', 'targets': array([  3,   4, 834,  60,   7,   1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_TOKEN:public int getArgmin() { final MutableInt argmin = new MutableInt(-1); final MutableDouble min <extra_id_0> this.iterate(new FnIntDoubleToVoid() { public void call(int idx, double val) { if (val < min.v) { argmin.v = idx; min.v = val; } } }); return argmin.v; }', 'inputs': array([    3,  7641,    15,  2591,    56,  4569,    35,     3, 10399,\n",
            "         769,    16,     7,    44,  4325,   890,   476,   769,    11,\n",
            "          24,  4325,   890,  6953,    44,  4325,   759,   700, 32099,\n",
            "          23,     4, 25510,     5,    74,     3,  6273,   890,   759,\n",
            "         129,  1870,    16,     7,    12,    20,   472,     5,    53,\n",
            "        2747,     9,   168,   752,     8,     7,    21,    17,  1102,\n",
            "         136,   700,     4,   291,     8,     7,   476,   769,     4,\n",
            "         291,    11,  2747,    13,   700,     4,   291,    11,   752,\n",
            "          13,     6,     6,     6,    10,    14,   476,   769,     4,\n",
            "         291,    13,     6,     1], dtype=int32), 'targets_pretokenized': b'= new MutableDouble(Double.POSITIVE_INFINITY);', 'targets': array([   11,    24,  4325,   759,     5,   759,     4, 10210,    15,\n",
            "       11469,     2,    10,     1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIe-u5l9ke6x"
      },
      "source": [
        "JAVA BLOCK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr0TT18ejMtY",
        "outputId": "d3e78f75-42cd-415f-f36b-cd628fab664f"
      },
      "source": [
        "def nq_java_block(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_java_block[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw valid examples...\")\n",
        "for ex in tfds.as_numpy(nq_java_block(\"validation\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw valid examples...\n",
            "{'input': b'public Object createField(String name) { Object reader = _fieldMap.get(name); if (reader == null) <extra_id_0> return reader; }', 'output': b'reader = NullFieldDeserializer.DESER;'}\n",
            "{'input': b'@Nonnull public static JSInvocation invoke (@Nonnull final JQueryInvocation aJQueryInvocation, @Nonnull final JSAssocArray aOptions) <extra_id_0>', 'output': b'{ return invoke (aJQueryInvocation).arg (aOptions); }'}\n",
            "{'input': b'public static String presentMinMaxCount(long minmax) { if (minmax == Long.MAX_VALUE || minmax == Long.MIN_VALUE) <extra_id_0> return String.valueOf(minmax); }', 'output': b'{ return UNDEF_STRING; }'}\n",
            "{'input': b'@Override public NonBottomTypeNode<ElkClass, ElkNamedIndividual> getCreateNode( final Collection<? extends ElkClass> members) <extra_id_0>', 'output': b'{ return getCreateUpdateableTypeNode( classTaxonomy_.getCreateNode(members)); }'}\n",
            "{'input': b'public static JsonException typeMismatch(Object indexOrName, Object actual, String requiredType, boolean mode) throws JsonException { if (actual == null) <extra_id_0> else { throw new JsonException(\"Value \" + actual + \" at \" + indexOrName + \" of type \" + actual.getClass().getName() + \" cannot be converted to \" + requiredType + \". Strict mode is: \" + mode); } }', 'output': b'{ throw new JsonException(\"Value at \" + indexOrName + \" is null.\"); }'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq0uLYNTjM9z"
      },
      "source": [
        "def java_block_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['JAVA_BLOCK:' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji4u8yhqjNER",
        "outputId": "19778543-8009-445f-d9a1-c71701b496a6"
      },
      "source": [
        "t5.data.TaskRegistry.remove('java_block')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"java_block\",\n",
        "    dataset_fn=nq_java_block,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[java_block_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_java_block\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f776116db00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG09lDZdjNKr",
        "outputId": "ff5ccece-4b13-425e-c3d9-52e65d62c031"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"java_block\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 256, \"targets\": 256})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'inputs_pretokenized': b'JAVA_BLOCK:@Override public Optional<TimeSeriesCollection> getPreviousCollection(int n) { if (n < 0) throw new IllegalArgumentException(\"cannot look into the future\"); if (n == 0) return Optional.of(getCurrentCollection()); if (n - 1 >= previous_.size()) <extra_id_0> return Optional.of(previous_.get(n - 1)); }', 'inputs': array([    3,  7641,    15,  3517,    56,  2098,    27,    12,   730,\n",
            "          25, 16445,   387,    29, 15550,   387,     5,    53,   446,\n",
            "           8,     7,    21,    17,   127,   136,   178,    78,    24,\n",
            "         381,    38,    28, 10153,  5972,  2378,    62,  2639,    46,\n",
            "          21,    17,   127,    40,   178,    14,   730,     4,   579,\n",
            "           5,  1134,   387,    39,    21,    17,   127,   139,   279,\n",
            "         453,  1805,    15,     4,   134,    60, 32099,    14,   730,\n",
            "           4,   579,     5,  3500,    15,     4,    33,     5,   127,\n",
            "         139,  3792,     6,     1], dtype=int32), 'targets_pretokenized': b'return Optional.empty();', 'targets': array([  14,  730,    4, 1571,   18,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_BLOCK:private void readEmptyLine(BufferedSource source) throws IOException { String line = source.readUtf8LineStrict(); if (line.length() != 0) <extra_id_0> }', 'inputs': array([    3,  7641,    15,  3517,    56,  8797,    20,   384,  1178,\n",
            "         481,     5,  8562,   318,   345,     8,    42,   115,     7,\n",
            "          26,   626,    11,   345,     4,   471,  4456,     2,   481,\n",
            "        5541,    18,    21,    17,   687,     4,   105,    16,    49,\n",
            "         178, 32099,     6,     1], dtype=int32), 'targets_pretokenized': b'throw new IllegalStateException(\"Expected empty but was: \" + line);', 'targets': array([  78,   24,  857,   38,   28, 1783, 1155, 1127,  945,   56,   32,\n",
            "         34,  626,   10,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_BLOCK:@Factory public static <T extends View> Matcher<T> isOnScreen(T rootView) <extra_id_0>', 'inputs': array([    3,  7641,    15,  3517,    56,  2098,   149,    12,    48,\n",
            "         136,    70,   324,   886,    29,  2908,    25,    70,    29,\n",
            "          69, 13945,     5,    70, 15694,     8, 32099,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'{ return new IsOnScreen<T>(rootView); }', 'targets': array([    7,    14,    24,     3,  1045, 13945,    25,    70,    29,\n",
            "           5,  1092,   143,    10,     6,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_BLOCK:public boolean isExistsIndex(String indexName) { IndicesExistsResponse response = getClient().admin().indices().exists( new IndicesExistsRequest().indices(new String[]<extra_id_0>)).actionGet(); return response.isExists(); }', 'inputs': array([    3,  7641,    15,  3517,    56,  4569,    45,    69,  1841,\n",
            "         163,     5,    31, 10338,     8,     7,     3,  3801,  1841,\n",
            "         164,   250,    11,  4578,    37,  2746,    37,  7033,    37,\n",
            "        1090,     5,    24,     3,  3801,  1841,   125,    37,  7033,\n",
            "           5,    74,    26,    61,    25,  4837,    15,   111,    15,\n",
            "         148,    29,     8,     8,     4, 24844,    18,    14,   250,\n",
            "           4,   112,  1841,    18,     6,     1], dtype=int32), 'targets_pretokenized': b'{indexName}', 'targets': array([    7, 13556,  1105,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_BLOCK:public List<WorkUnit> getWorkUnits() { ImmutableList.Builder<WorkUnit> allWorkUnits = ImmutableList.builder(); for (List<WorkUnit> workUnits : this.workUnitsMap.values()) <extra_id_0> return allWorkUnits.build(); }', 'inputs': array([    3,  7641,    15,  3517,    56,  4569,    85,    25,  1847,\n",
            "        1006,    29,    41,  1847,  4423,    16,     7,  3184,     4,\n",
            "         141,    25,  1847,  1006,    29,   506,  1847,  4423,    11,\n",
            "        3184,     4,   534,    18,    50,    17,    71,    25,  1847,\n",
            "        1006,    29,  2346,  4423,    58,    23,     4,  4739,  4423,\n",
            "         100,     4,   457,    60, 32099,    14,   506,  1847,  4423,\n",
            "           4,   352,    18,     6,     1], dtype=int32), 'targets_pretokenized': b'{ allWorkUnits.addAll(workUnits); }', 'targets': array([   7,  506, 1847, 4423,    4,  771,    5, 4739, 4423,   10,    6,\n",
            "          1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz_Gxq_4khQt"
      },
      "source": [
        "ANDROID CONSTRUCT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNwnQAMVjNdy",
        "outputId": "a7d23ab2-798e-4dd4-fbb7-b5233d9f3221"
      },
      "source": [
        "def nq_android_construct(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "   # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_android_construct[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(nq_android_construct(\"train\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw train examples...\n",
            "{'input': b'private void writeToFile(final String content) { if ( <extra_id_0>) { return; } try { System.err.println(content); File f = new File(OUTPUT_FILE); f.delete(); FileWriter fstream = new FileWriter(OUTPUT_FILE); BufferedWriter out = new BufferedWriter(fstream); out.write(content); out.close(); } catch (Exception e) { e.printStackTrace(); } }', 'output': b'!WRITE_TO_FILE'}\n",
            "{'input': b'private void writeToFile(final String content) { if (!WRITE_TO_FILE) { return; } try { System.err.println(content); File f = new File(OUTPUT_FILE); f.delete(); FileWriter fstream = new FileWriter(OUTPUT_FILE); BufferedWriter out = new BufferedWriter(fstream); out.write(content); out.close(); } catch ( <extra_id_0>) { e.printStackTrace(); } }', 'output': b'Exception e'}\n",
            "{'input': b'private void writeToFile(final String content) { if (!WRITE_TO_FILE) { return; } try { System.err.println(content); File f = new File( <extra_id_0>); f.delete(); FileWriter fstream = new FileWriter(OUTPUT_FILE); BufferedWriter out = new BufferedWriter(fstream); out.write(content); out.close(); } catch (Exception e) { e.printStackTrace(); } }', 'output': b'OUTPUT_FILE'}\n",
            "{'input': b'private void writeToFile(final String content) { if (!WRITE_TO_FILE) { return; } try { System.err.println( <extra_id_0>); File f = new File(OUTPUT_FILE); f.delete(); FileWriter fstream = new FileWriter(OUTPUT_FILE); BufferedWriter out = new BufferedWriter(fstream); out.write(content); out.close(); } catch (Exception e) { e.printStackTrace(); } }', 'output': b'content'}\n",
            "{'input': b'private void writeToFile(final String content) { if (!WRITE_TO_FILE) { return; } try { System.err.println(content); File f = new File(OUTPUT_FILE); f.delete(); FileWriter fstream = new FileWriter(OUTPUT_FILE); BufferedWriter out = new BufferedWriter(fstream); out.write( <extra_id_0>); out.close(); } catch (Exception e) { e.printStackTrace(); } }', 'output': b'content'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sBEViP5jNja"
      },
      "source": [
        "def android_construct_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['ANDROID_CONSTRUCT:' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP_VXjC6jNpp",
        "outputId": "2be77815-aefc-44b2-887b-5f46cab28be7"
      },
      "source": [
        "t5.data.TaskRegistry.remove('android_construct')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"android_construct\",\n",
        "    dataset_fn=nq_android_construct,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[android_construct_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_android_construct\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f776119c390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOWFYL7KjNwd",
        "outputId": "895bd58a-ac30-4123-a8a5-22e2215fd154"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"android_construct\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 256, \"targets\": 256})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'ANDROID_CONSTRUCT:public void onReceive(Context context, Intent intent) { if(GameActivity.ACTION_PAGE_SELECTED.equals(intent.getAction())) if(action != null && action.isActive()) action.finish(); if(LocalEvents.ACTION_PLAYER_ADD.equals(intent.getAction()) || LocalEvents.ACTION_PLAYER_EDIT.equals( <extra_id_0>) || LocalEvents.ACTION_PLAYER_REMOVE.equals(intent.getAction())) playersAdapter.notifyDataSetChanged(); }', 'inputs': array([    3, 16446,    15,  5071, 17558,    56,  4569,    20,  6431,\n",
            "           5,    92,   130,     9,   604,   576,     8,     7,    21,\n",
            "           5,  2040,   435,     4,  1023,    15,  3497,    15,  9738,\n",
            "           4,   117,     5,  1482,     4,  2677,   459,    21,     5,\n",
            "         915,    49,    30,    91,   647,     4,  5649,    60,   647,\n",
            "           4,  3835,    18,    21,     5,   959,  1314,     4,  1023,\n",
            "          15,  3882,     2,  1387,    15,  4735,     4,   117,     5,\n",
            "        1482,     4,  2677,    60,     3,     2,  3671,  1314,     4,\n",
            "        1023,    15,  3882,     2,  1387,    15,  7282,     4,   117,\n",
            "           5, 32099,     8,     3,     2,  3671,  1314,     4,  1023,\n",
            "          15,  3882,     2,  1387,    15,  8333,     4,   117,     5,\n",
            "        1482,     4,  2677,   459,  7275,   442,     4,  8072,   566,\n",
            "          18,     6,     1], dtype=int32), 'targets_pretokenized': b'intent.getAction()', 'targets': array([ 576,    4, 2677,   16,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_CONSTRUCT:@MediumTest public void goToStart() { solo.assertCurrentActivity(\"wrong activity\", ContactsActivity.class); String lastContact = (String) ((TalkingButton) solo.getView(R.id.contact_name)).getText(); String currContact = lastContact; do { lastContact = currContact; GestureTestUtils.flingLeft(this); currContact = (String) ((TalkingButton) solo.getView( <extra_id_0>)).getText(); } while (!currContact.equals(lastContact)); }', 'inputs': array([    3, 16446,    15,  5071, 17558,    56,  2098, 11942,    12,\n",
            "          20, 13441,   461,    16,     7, 15128,     4,  2340,  1211,\n",
            "         435,    28, 20554,  1028,    43,  8512,   435,     4,    88,\n",
            "          10,    26,   555,  1350,    11,    17,    31,     8,    17,\n",
            "           5, 13994,   150,   448,     8, 15128,     4,  4883,     5,\n",
            "         144,     4,   111,     4,  4208,    15,    98,     8,     8,\n",
            "           4,   812,    18,    26,  4716,  1350,    11,   555,  1350,\n",
            "          13,   396,     7,   555,  1350,    11,  4716,  1350,    13,\n",
            "           3,  6730,  3887,     4, 23150,  1566,     5,    75,    10,\n",
            "        4716,  1350,    11,    17,    31,     8,    17,     5, 13994,\n",
            "         150,   448,     8, 15128,     4,  4883,     5, 32099,     8,\n",
            "           8,     4,   812,    18,     6,   317,   124,  6159,  1350,\n",
            "           4,   117,     5,   944,  1350,    79,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'R.id.contact_name', 'targets': array([ 544,    4,  111,    4, 4208,   15,   98,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_CONSTRUCT:public void updatePresence(String resource, Presence presence) { synchronized (this.presences) { this.presences.put( <extra_id_0>); } }', 'inputs': array([    3, 16446,    15,  5071, 17558,    56,  4569,    20,   233,\n",
            "        5557,     5,    31,   623,     9,     3,  5557, 16462,     8,\n",
            "           7,   310,    17,    75,     4, 24763,    22,     8,     7,\n",
            "          23,     4, 24763,    22,     4,   120,     5, 32099,    10,\n",
            "           6,     6,     1], dtype=int32), 'targets_pretokenized': b'resource, presence', 'targets': array([  623,     9, 16462,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_CONSTRUCT:private void setTimerSleepMode(long delay){ if( <extra_id_0>){ timerTask.cancel(); } timerTask = new TimerSleepMode(this); timer.schedule(timerTask, delay); }', 'inputs': array([    3, 16446,    15,  5071, 17558,    56,  8797,    20,    55,\n",
            "        1734,  8128,   270,     5,   288,  3064,   212,    21,     5,\n",
            "       32099,   212,  3258,   389,     4,  1753,    18,     6,  3258,\n",
            "         389,    11,    24, 10345,  8128,   270,     5,    75,    10,\n",
            "        3258,     4,  3038,     5,  6531,   389,     9,  3064,    10,\n",
            "           6,     1], dtype=int32), 'targets_pretokenized': b'timerTask!=null', 'targets': array([3258,  389, 1798,  180,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_CONSTRUCT:protected IdentifyResult[] doInBackground(IdentifyParameters... params) { if ( <extra_id_0>) { IdentifyParameters mParams = params[0]; try { M_Result = task.execute(mParams); } catch (Exception e) { e.printStackTrace(); } } return M_Result; }', 'inputs': array([    3, 16446,    15,  5071, 17558,    56, 18728,     3,  5451,\n",
            "        3647,   195,    61,  7088,     5,  5451,  3647,   542,     4,\n",
            "           4,     4,   469,     8,     7,    21,    17, 32099,     8,\n",
            "           7,     3,  5451,  3647,   542,    54,   803,    11,   469,\n",
            "        1659,    93,     7,  1653,    15,   195,    11,   845,     4,\n",
            "         784,     5,    87,   803,    10,     6,    97,    17,    38,\n",
            "          57,     8,     7,    57,     4,   864,    18,     6,     6,\n",
            "          14,  1653,    15,   195,    13,     6,     1], dtype=int32), 'targets_pretokenized': b'params != null && params.length > 0', 'targets': array([469,  49,  30,  91, 469,   4, 105,   3,  29, 157,   1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ9H1D-KngJy"
      },
      "source": [
        "ANDROID TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgi_2yd-nb4Y",
        "outputId": "5a503d53-3485-45e9-8b7c-9d02b807761e"
      },
      "source": [
        "def nq_android_token(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_android_token[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw valid examples...\")\n",
        "for ex in tfds.as_numpy(nq_android_token(\"validation\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw valid examples...\n",
            "{'input': b'public void register(Context context <extra_id_0> IntentFilter intentFilter = buildFilter(); try { register(context, intentFilter); }catch (IllegalArgumentException e){ Log.w(TAG, \"Error registering receiver. Receiver maybe already registered, unregistering to register again.\"); unregister(context); register(context, intentFilter); } }', 'output': b') {'}\n",
            "{'input': b'public void register(Context context) { IntentFilter intentFilter <extra_id_0> try { register(context, intentFilter); }catch (IllegalArgumentException e){ Log.w(TAG, \"Error registering receiver. Receiver maybe already registered, unregistering to register again.\"); unregister(context); register(context, intentFilter); } }', 'output': b'= buildFilter();'}\n",
            "{'input': b'public void register(Context context) { IntentFilter intentFilter = buildFilter(); try <extra_id_0> register(context, intentFilter); }catch (IllegalArgumentException e){ Log.w(TAG, \"Error registering receiver. Receiver maybe already registered, unregistering to register again.\"); unregister(context); register(context, intentFilter); } }', 'output': b'{'}\n",
            "{'input': b'public void register(Context context) { IntentFilter intentFilter = buildFilter(); try { register(context, intentFilter <extra_id_0> }catch (IllegalArgumentException e){ Log.w(TAG, \"Error registering receiver. Receiver maybe already registered, unregistering to register again.\"); unregister(context); register(context, intentFilter); } }', 'output': b');'}\n",
            "{'input': b'public void register(Context context) { IntentFilter intentFilter = buildFilter(); try { register(context, intentFilter); }catch (IllegalArgumentException <extra_id_0> Log.w(TAG, \"Error registering receiver. Receiver maybe already registered, unregistering to register again.\"); unregister(context); register(context, intentFilter); } }', 'output': b'e){'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcKSDpJrnb_X"
      },
      "source": [
        "def android_token_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['ANDROID_TOKEN:' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvwEpdZIjN_9",
        "outputId": "ca4b10d2-3c80-4e97-a30f-eac1aae7b61b"
      },
      "source": [
        "t5.data.TaskRegistry.remove('android_token')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"android_token\",\n",
        "    dataset_fn=nq_android_token,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[android_token_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_android_token\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f776117df98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6z53ZuUpT3f",
        "outputId": "340598bf-d090-4fcd-a0c2-75ee3f6aec58"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"android_token\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 256, \"targets\": 256})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'ANDROID_TOKEN:private void onDrag(MotionEvent event) { final int pointerIndex = event.findPointerIndex(_activePointerId); if (pointerIndex == -1) return; final float x = event.getX <extra_id_0> final float y = event.getY(pointerIndex); _translateX += (x - _lastTouchX); _translateY += (y - _lastTouchY); invalidate(); _lastTouchX = x; _lastTouchY = y; }', 'inputs': array([    3, 16446,    15,  2591,    56,  8797,    20,   170,  2943,\n",
            "           5,  6119,   209,     8,     7,    44,    35,  4635,   163,\n",
            "          11,   209,     4,   714,  1521,   163,     5,    15,  2231,\n",
            "        1521,    68,    10,    21,    17,  7358,   163,    40,  1324,\n",
            "          14,    13,    44,   245,   205,    11,   209,     4,    33,\n",
            "           2, 32099,    44,   245,   240,    11,   209,     4,    33,\n",
            "           2,     5,  7358,   163,    10,     3,    15,  3625,     2,\n",
            "         470,    17,   138,   139,     3,    15,   944,  3447,     2,\n",
            "          10,     3,    15,  3625,     2,   470,    17,   264,   139,\n",
            "           3,    15,   944,  3447,     2,    10,  3441,    18,     3,\n",
            "          15,   944,  3447,     2,    11,   205,    13,     3,    15,\n",
            "         944,  3447,     2,    11,   240,    13,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'(pointerIndex);', 'targets': array([  17, 7358,  163,   10,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_TOKEN:public static FilterView create(Context context, String boardName, ButtonClickListener listener) { FilterView view = new FilterView(context, null); view.setBoardName(boardName); view.setClickListener(listener) <extra_id_0> return view; }', 'inputs': array([    3, 16446,    15,  2591,    56,  4569,    48,     3,   251,\n",
            "         143,   131,     5,    92,   130,     9,    26,  7813,    66,\n",
            "           9,     3,   448,  5073,   499,     8,     7,     3,   251,\n",
            "         143,   403,    11,    24,     3,   251,   143,     5,   201,\n",
            "           9,    30,    10,   403,     4,    63,  4171,    66,     5,\n",
            "        5376,    66,    10,   403,     4,    63,  5073,     5,  1252,\n",
            "           8, 32099,    14,   403,    13,     6,     1], dtype=int32), 'targets_pretokenized': b';', 'targets': array([ 3, 13,  1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_TOKEN:public Client(int playerId,Socket socket,ClientReadingThread readingRunable,Thread readingThread){ this.playerId=playerId; this.socket=socket; try{ this.outputStream=socket.getOutputStream(); this.dataOutputStream=new DataOutputStream(outputStream); }catch(Exception e){} this.readingRunable <extra_id_0> this.readingThread=readingThread; }', 'inputs': array([    3, 16446,    15,  2591,    56,  4569,  2797,     5,    53,\n",
            "       18281,     9,  2017,  2621,     9,   229,  4454,   595,  5168,\n",
            "        1403,   367,     9,   595,  5168,   595,   212,    23,     4,\n",
            "       19050,   161, 19050,    13,    23,     4,  4400,   161,  4400,\n",
            "          13,    93,   683,    23,     4,  9034,   161,  4400,     4,\n",
            "        6357,    18,    23,     4,   258,   727,   161,    74,     3,\n",
            "        5711,     5,  9034,    10,     6,  4629,     5,    38,    57,\n",
            "       11571,    23,     4, 17747,  1403,   367, 32099,    23,     4,\n",
            "       17747,   595,   161, 17747,   595,    13,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'=readingRunable;', 'targets': array([   11, 17747,  1403,   367,    13,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_TOKEN:public boolean onPreferenceChange(Preference preference, Object o) { switch (preference.getKey()) { case Constants.PREF_DISPLAY_LANGUAGE: new MaterialDialog.Builder(getActivity()) .title(getString(R.string. <extra_id_0> .content(getString(R.string.restart_app_content)) .positiveText(getString(android.R.string.ok)) .build() .show(); break; } return true; }', 'inputs': array([    3, 16446,    15,  2591,    56,  4569,    45,   170, 12256,\n",
            "           5,   986,  3115,     9,   102,   207,     8,     7,   695,\n",
            "          17,  4971,     4,   641,    60,     7,   234,  5040,     4,\n",
            "        3579,    15,  4402,     2,    15,  8615,    56,    24,  2887,\n",
            "         599,     4,   141,     5,  1926,    60,     3,     4,   982,\n",
            "           5,   416,     5,   144,     4,   383,     4, 32099,     3,\n",
            "           4,   921,     5,   416,     5,   144,     4,   383,     4,\n",
            "       12959,    15,  1242,    15,   921,     8,     8,     3,     4,\n",
            "       16167,   204,     5,   416,     5,  1490,     4,   144,     4,\n",
            "         383,     4,  2185,     8,     8,     3,     4,   352,    16,\n",
            "           3,     4,   748,    18,   591,    13,     6,    14,    89,\n",
            "          13,     6,     1], dtype=int32), 'targets_pretokenized': b'restart_app))', 'targets': array([6570,   15, 1242,    8,    8,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_TOKEN:protected IdentifyResult[] doInBackground(IdentifyParameters... params) { if (params != null && params.length > 0) { IdentifyParameters mParams = params[0]; try { M_Result <extra_id_0> } catch (Exception e) { e.printStackTrace(); } } return M_Result; }', 'inputs': array([    3, 16446,    15,  2591,    56, 18728,     3,  5451,  3647,\n",
            "         195,    61,  7088,     5,  5451,  3647,   542,     4,     4,\n",
            "           4,   469,     8,     7,    21,    17,  1531,    49,    30,\n",
            "          91,   469,     4,   105,     3,    29,   178,     7,     3,\n",
            "        5451,  3647,   542,    54,   803,    11,   469,  1659,    93,\n",
            "           7,  1653,    15,   195, 32099,     6,    97,    17,    38,\n",
            "          57,     8,     7,    57,     4,   864,    18,     6,     6,\n",
            "          14,  1653,    15,   195,    13,     6,     1], dtype=int32), 'targets_pretokenized': b'= task.execute(mParams);', 'targets': array([ 11, 845,   4, 784,   5,  87, 803,  10,   1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q3xYhUwoBC6"
      },
      "source": [
        "ANDROID BLOCK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqvJtXAKjOFn",
        "outputId": "01ac585c-b66e-4f23-ee3c-446c0467983e"
      },
      "source": [
        "def nq_android_block(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_android_block[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw valid examples...\")\n",
        "for ex in tfds.as_numpy(nq_android_block(\"validation\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw valid examples...\n",
            "{'input': b'public void update() { if(Gdx.input.isKeyPressed(Keys.LEFT))<extra_id_0> if(Gdx.input.isKeyPressed(Keys.RIGHT)){ bucket.x += 200 * Gdx.graphics.getDeltaTime(); } if (bucket.x < 0) bucket.x = 0; if (bucket.x > 320 - 64) bucket.x = 320 - 64; }', 'output': b'{ bucket.x -= 200 * Gdx.graphics.getDeltaTime(); }'}\n",
            "{'input': b'public void update() { if(Gdx.input.isKeyPressed(Keys.LEFT)){ bucket.x -= 200 * Gdx.graphics.getDeltaTime(); } if(Gdx.input.isKeyPressed(Keys.RIGHT))<extra_id_0> if (bucket.x < 0) bucket.x = 0; if (bucket.x > 320 - 64) bucket.x = 320 - 64; }', 'output': b'{ bucket.x += 200 * Gdx.graphics.getDeltaTime(); }'}\n",
            "{'input': b'public void update() { if(Gdx.input.isKeyPressed(Keys.LEFT)){ bucket.x -= 200 * Gdx.graphics.getDeltaTime(); } if(Gdx.input.isKeyPressed(Keys.RIGHT)){ bucket.x += 200 * Gdx.graphics.getDeltaTime(); } if (bucket.x < 0) <extra_id_0> if (bucket.x > 320 - 64) bucket.x = 320 - 64; }', 'output': b'bucket.x = 0;'}\n",
            "{'input': b'public void update() { if(Gdx.input.isKeyPressed(Keys.LEFT)){ bucket.x -= 200 * Gdx.graphics.getDeltaTime(); } if(Gdx.input.isKeyPressed(Keys.RIGHT)){ bucket.x += 200 * Gdx.graphics.getDeltaTime(); } if (bucket.x < 0) bucket.x = 0; if (bucket.x > 320 - 64) <extra_id_0> }', 'output': b'bucket.x = 320 - 64;'}\n",
            "{'input': b'public String getTitle() throws IOException, StringIndexOutOfBoundsException { Map<String, String> data = getMetadata(); if (data == null || !data.containsKey(\"StreamTitle\")) <extra_id_0> String streamTitle = data.get(\"StreamTitle\"); String artist = streamTitle.substring(streamTitle.indexOf(\"-\") + 1); return artist.trim(); }', 'output': b'{ return \"\"; }'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvADtjcHoGCM"
      },
      "source": [
        "def android_block_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['ANDROID_BLOCK:' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY6Cr6OyoGLR",
        "outputId": "862094f7-442b-4f58-adfc-cddd1df047c3"
      },
      "source": [
        "t5.data.TaskRegistry.remove('android_block')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"android_block\",\n",
        "    dataset_fn=nq_android_block,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[android_block_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_android_block\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f7761206c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIpCwr6FjOMd",
        "outputId": "9217954d-f145-49f4-f6d0-fad71de26d19"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"android_block\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 256, \"targets\": 256})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'ANDROID_BLOCK:@Override public void onPrepared(MediaPlayer mp) { progressDialog.dismiss(); if (-1 != mCurrentPosition) <extra_id_0> mVideoView.start(); }', 'inputs': array([    3, 16446,    15,  3517,    56,  2098,    27,    12,    20,\n",
            "         170,  5609,     5,  6238,  8212,     8,     7, 12898,     4,\n",
            "        3875,    18,    21,    17,   802,    49,  2982,   392,     8,\n",
            "       32099,    54, 17649,     4,   373,    18,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'{ mVideoView.seekTo(mCurrentPosition); }', 'targets': array([    7,    54, 17649,     4, 14206,     5,  4399,   392,    10,\n",
            "           6,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_BLOCK:private void spinnerSelect(LibOpenConnect.FormOpt opt, int index) { LibOpenConnect.FormChoice fc = opt.choices.get((int)index); String s = fc.name != null ? fc.name : \"\"; if (opt.userData == null) <extra_id_0> else if (!s.equals(opt.userData)) { opt.value = s; mAlert.dismiss(); finish(LibOpenConnect.OC_FORM_RESULT_NEWGROUP); } }', 'inputs': array([    3, 16446,    15,  3517,    56,  8797,    20, 10332,  1495,\n",
            "           5,  4172,  1158,  2306,     4,   696,  5866,  4562,     9,\n",
            "          35,   242,     8,     7, 17843,  1158,  2306,     4,   696,\n",
            "        3708,  9100,    11,  4562,     4, 12057,    22,     4,    33,\n",
            "           5,     5,    53,     8,   311,    10,    26,     3,    22,\n",
            "          11,  9100,     4,    98,    49,    30,     3,     2,  9100,\n",
            "           4,    98,    58,   903,    21,    17,  3845,     4,   418,\n",
            "          99,    40,    30,     8, 32099,    77,    21,   124,    22,\n",
            "           4,   117,     5,  3845,     4,   418,    99,     8,     8,\n",
            "           7,  4562,     4,   122,    11,     3,    22,    13,    54,\n",
            "        2568,     4,  3875,    18,  2029,     5,  4172,  1158,  2306,\n",
            "           4,  6891,    15,  7146,    15,  2543,    15,  2975,  2408,\n",
            "          10,     6,     6,     1], dtype=int32), 'targets_pretokenized': b'{ opt.userData = s; }', 'targets': array([   7, 4562,    4,  418,   99,   11,    3,   22,   13,    6,    1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_BLOCK:public void checkIfMocked(float x, float y) { if (isActive() && mDevil.getHitbox().isInside(x, y)) { if (mDevil.talk(R.array.devil_talk_mock, 0.05)) <extra_id_0> } }', 'inputs': array([    3, 16446,    15,  3517,    56,  4569,    20, 11247, 22776,\n",
            "           5,   620,   205,     9,   245,   240,     8,     7,    21,\n",
            "          17,  5649,    16,    91,    54,  8244,  3506,     4,    33,\n",
            "        3905,  2202,    37, 21938,     5,   138,     9,   240,     8,\n",
            "           8,     7,    21,    17,    87,  8244,  3506,     4, 12925,\n",
            "           5,   144,     4,  1046,     4,  7684,  3506,    15, 12925,\n",
            "          15,  2076,     9,  1524,     2,     8,     8, 32099,     6,\n",
            "           6,     1], dtype=int32), 'targets_pretokenized': b'{ mConfig.mAchievementGameData.increment(AchievementSnow .KEY_GAME_DEVIL_TALK_ANNOYED_COUNT, 1L, 0L); }', 'targets': array([    7,    54,   151,     4,    87,  9449,  2040,    99,     4,\n",
            "        4752,     5,  9449, 22990,     3,     4,   370,     2,    15,\n",
            "       19565,    15, 21495,  7792,    15,  7699, 18658,    15,  3612,\n",
            "        1413,     2,  1011,    15,  2407,     9,   279,   215,     9,\n",
            "         157,   215,    10,     6,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_BLOCK:public void remove(List<SearchResult> results) { mResults.beginBatchedUpdates(); for (SearchResult result : results) <extra_id_0> mResults.endBatchedUpdates(); }', 'inputs': array([    3, 16446,    15,  3517,    56,  4569,    20,   424,     5,\n",
            "          71,    25,  7370,    29,   984,     8,     7,    54,  1126,\n",
            "           4,  3090,  1346,   159,  3979,    18,    50,    17,  7370,\n",
            "          84,    58,   984,     8, 32099,    54,  1126,     4,   852,\n",
            "        1346,   159,  3979,    18,     6,     1], dtype=int32), 'targets_pretokenized': b'{ mResults.remove(result); }', 'targets': array([   7,   54, 1126,    4,  252,    5,  360,   10,    6,    1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_BLOCK:public static String toSqlList(List<Long> longs) { if (longs == null || longs.isEmpty()) <extra_id_0> String list = \"\"; for (Long theLong : longs) { if (list.length() > 0) { list += \",\"; } list += Long.toString(theLong); } return list; }', 'inputs': array([    3, 16446,    15,  3517,    56,  4569,    48,    26,    81,\n",
            "        1950,    71,     5,    71,    25,   397,    29,   126,    22,\n",
            "           8,     7,    21,    17,   288,    22,    40,    30,     3,\n",
            "           2,   126,    22,     4,   280,    60, 32099,    26,   247,\n",
            "          11,   903,    50,    17,   397,    62,   397,    58,   126,\n",
            "          22,     8,     7,    21,    17,   430,     4,   105,    16,\n",
            "           3,    29,   178,     7,   247,   470,  4521,    13,     6,\n",
            "         247,   470,   493,     4,   123,     5,  1882,   397,    10,\n",
            "           6,    14,   247,    13,     6,     1], dtype=int32), 'targets_pretokenized': b'{ return \"0\"; }', 'targets': array([   7,   14, 7472,   13,    6,    1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0chadICjOT_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-MqgKiIHA9X"
      },
      "source": [
        "### Hyper Parameter tuning\n",
        "You can run the HP tuning using the following cells.  \n",
        "Please set the correct path of the variable *MODEL_DIR* (the path to save the pretrained model in), *PATH_GIN_FILE* (the gin file configuration for this HP tuning) and *PRETRAINED_DIR* (the folder that contains the pretrained model).  \n",
        "**Keep attention** to change the *pretrained_model_dir* in finetune step (if you are starting the HP tuning from scratch you have to set the value *PRETRAINED_DIR*, if you are restarting the HP tuning from a previous saved checkpoint you have to set the value *MODEL_DIR*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz1a1TxFNKmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc37db37-3d9e-47e2-e503-623a419fe34e"
      },
      "source": [
        "def _rate_num_input_examples(task):\n",
        "  if \"train\" in task.splits:\n",
        "    return float(task.num_input_examples(\"train\"))\n",
        "  elif \"validation\" in task.splits:\n",
        "    return float(task.num_input_examples(\"validation\"))\n",
        "  else:\n",
        "    raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))\n",
        "\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"all_tasks\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"all_tasks\",\n",
        "    [\"java_construct\", \"java_token\", \"java_block\", \"android_construct\", \"android_token\", \"android_block\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        "     #default_rate=1.0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.seqio.dataset_providers.Mixture at 0x7f7761190748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSh7F89Zqb6"
      },
      "source": [
        "from mesh_tensorflow.transformer.learning_rate_schedules import truncated_rsqrt\n",
        "\n",
        "MODEL_SIZE = \"small\" \n",
        "\n",
        "# Set the folder where the checkpoints and all the others information will be writed\n",
        "MODEL_DIR = 'gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/model'\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://bucket_comment_completion/Matteo/pretrained_with_masking'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 16),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = t5.models.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    learning_rate_schedule = truncated_rsqrt,\n",
        "    sequence_length={\"inputs\": 256, \"targets\": 256},\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oHp5ScE7nf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95cade2-5464-418b-e40e-f6f9b342b4e2"
      },
      "source": [
        "PATH_GIN_FILE = 'gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/operative_config.gin'\n",
        "import gin\n",
        "\n",
        "with gin.unlock_config():\n",
        "    gin.parse_config_file(PATH_GIN_FILE)\n",
        "    #RUN FINE-TUNING\n",
        "    FINETUNE_STEPS = 100000\n",
        "    model.finetune(\n",
        "        mixture_or_task_name=\"all_tasks\",\n",
        "        pretrained_model_dir=MODEL_DIR,\n",
        "        finetune_steps=FINETUNE_STEPS\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/operative_config.gin\n",
            "INFO:root:system_path_file_exists:gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/model/operative_config.gin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.116.164.242:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.116.164.242:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.116.164.242:8470', '_evaluation_master': 'grpc://10.116.164.242:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f7761000cc0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.116.164.242:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.116.164.242:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 6598689243313744933)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -923074147476835314)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5050315219021864401)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6293659895603769580)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5288921074508541216)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4581337421087346231)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 435998198951455229)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6608991256697649084)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2116165111311579826)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 7876646814432248344)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6992092791074707207)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('heads', 'model'), ('batch', 'batch'), ('ensemble', 'ensemble'), ('d_ff', 'model'), ('experts', 'batch'), ('vocab', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f7762f91c18>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 105     Total size: 60691328         Total slice_size: 60691328       \n",
            "INFO:tensorflow:Counters:\n",
            "allreduce: 5.34e+08\n",
            " allreduce/[0]: 5.34e+08\n",
            "  allreduce/[0]/einsum_op: 4.84e+08\n",
            "  allreduce/[0]/reduce_op: 5.03e+07\n",
            "einsum: 1.93e+13\n",
            "einsum_unique: 1.93e+13\n",
            "output: 1.39e+11\n",
            " output/AddOperation: 2.22e+10\n",
            " output/BinaryOpWithBroadcasting: 1.95e+09\n",
            " output/BroadcastOperation: 7.7e+09\n",
            " output/Constant: 8\n",
            " output/EinsumOperation: 5.94e+10\n",
            " output/ImportOperation: 3.15e+06\n",
            " output/MinMaxOperation: 9.5e+06\n",
            " output/OneHotOperation: 6.52e+09\n",
            " output/RandomOperation: 2.02e+07\n",
            " output/RangeOperation: 4.1e+03\n",
            " output/ReduceOperation: 2e+09\n",
            " output/ReshapeOperation: 6.91e+09\n",
            " output/ScalarAddOperation: 4.99e+08\n",
            " output/ScalarMultiplyOperation: 1.5e+09\n",
            " output/ShiftOperation: 1.31e+05\n",
            " output/SlicewiseOperation: 2.5e+10\n",
            " output/StackOperation: 1.35e+06\n",
            " output/StackedVariable: 1.35e+06\n",
            " output/StopGradient: 4.52e+09\n",
            " output/UnstackOperation: 1.35e+06\n",
            " output/Variable: 4.84e+08\n",
            "output_unique: 1.33e+11\n",
            " output_unique/AddOperation: 2.2e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 1.94e+09\n",
            " output_unique/BroadcastOperation: 7.7e+09\n",
            " output_unique/Constant: 1\n",
            " output_unique/EinsumOperation: 5.69e+10\n",
            " output_unique/ImportOperation: 3.94e+05\n",
            " output_unique/MinMaxOperation: 1.25e+06\n",
            " output_unique/OneHotOperation: 6.34e+09\n",
            " output_unique/RandomOperation: 2.02e+07\n",
            " output_unique/RangeOperation: 512\n",
            " output_unique/ReduceOperation: 1.96e+09\n",
            " output_unique/ReshapeOperation: 6.91e+09\n",
            " output_unique/ScalarAddOperation: 6.42e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.47e+09\n",
            " output_unique/ShiftOperation: 1.31e+05\n",
            " output_unique/SlicewiseOperation: 2.28e+10\n",
            " output_unique/StackOperation: 1.69e+05\n",
            " output_unique/StackedVariable: 1.69e+05\n",
            " output_unique/StopGradient: 4.52e+09\n",
            " output_unique/UnstackOperation: 1.69e+05\n",
            " output_unique/Variable: 6.05e+07\n",
            "variables: 6.07e+07\n",
            " variables/trainable: 6.05e+07\n",
            " variables/untrainable: 1.85e+05\n",
            "INFO:tensorflow:Initializing variables from gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/model/model.ckpt-271400:\n",
            "INFO:tensorflow:Variables in gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/model/model.ckpt-271400 but not in graph:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Variables in graph but not in gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/model/model.ckpt-271400:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Bypassing TPUEstimator hook\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Starting the session.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/model/model.ckpt-271400\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1076: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:773: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 271400...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 271400 into gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 271400...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:loss = 0.013183594, step = 271500\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.012756348, step = 271600 (27.756 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.6028\n",
            "INFO:tensorflow:examples/sec: 922.317\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (2, 23)\n",
            "INFO:tensorflow:loss = 0.012817383, step = 271700 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8028\n",
            "INFO:tensorflow:examples/sec: 973.518\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.011413574, step = 271800 (27.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67666\n",
            "INFO:tensorflow:examples/sec: 941.226\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 48)\n",
            "INFO:tensorflow:loss = 0.0138549805, step = 271900 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80279\n",
            "INFO:tensorflow:examples/sec: 973.515\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01361084, step = 272000 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80302\n",
            "INFO:tensorflow:examples/sec: 973.574\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 77)\n",
            "INFO:tensorflow:loss = 0.013122559, step = 272100 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80279\n",
            "INFO:tensorflow:examples/sec: 973.515\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0126953125, step = 272200 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80305\n",
            "INFO:tensorflow:examples/sec: 973.58\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014709473, step = 272300 (27.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.6658\n",
            "INFO:tensorflow:examples/sec: 938.446\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 2)\n",
            "INFO:tensorflow:loss = 0.015136719, step = 272400 (26.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80217\n",
            "INFO:tensorflow:examples/sec: 973.356\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014526367, step = 272500 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80303\n",
            "INFO:tensorflow:examples/sec: 973.576\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (11, 31)\n",
            "INFO:tensorflow:loss = 0.012451172, step = 272600 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80265\n",
            "INFO:tensorflow:examples/sec: 973.478\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014099121, step = 272700 (27.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67926\n",
            "INFO:tensorflow:examples/sec: 941.891\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 56)\n",
            "INFO:tensorflow:loss = 0.015258789, step = 272800 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80284\n",
            "INFO:tensorflow:examples/sec: 973.526\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015136719, step = 272900 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80279\n",
            "INFO:tensorflow:examples/sec: 973.514\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (15, 85)\n",
            "INFO:tensorflow:loss = 0.014038086, step = 273000 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80282\n",
            "INFO:tensorflow:examples/sec: 973.521\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014831543, step = 273100 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.572\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.013244629, step = 273200 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80284\n",
            "INFO:tensorflow:examples/sec: 973.527\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (18, 10)\n",
            "INFO:tensorflow:loss = 0.013427734, step = 273300 (27.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67345\n",
            "INFO:tensorflow:examples/sec: 940.403\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014465332, step = 273400 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80288\n",
            "INFO:tensorflow:examples/sec: 973.537\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 39)\n",
            "INFO:tensorflow:loss = 0.016235352, step = 273500 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80266\n",
            "INFO:tensorflow:examples/sec: 973.481\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01361084, step = 273600 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80256\n",
            "INFO:tensorflow:examples/sec: 973.455\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (22, 68)\n",
            "INFO:tensorflow:loss = 0.014709473, step = 273700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80291\n",
            "INFO:tensorflow:examples/sec: 973.546\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014526367, step = 273800 (27.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67713\n",
            "INFO:tensorflow:examples/sec: 941.346\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 93)\n",
            "INFO:tensorflow:loss = 0.016357422, step = 273900 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80282\n",
            "INFO:tensorflow:examples/sec: 973.521\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014343262, step = 274000 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8032\n",
            "INFO:tensorflow:examples/sec: 973.619\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.013183594, step = 274100 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80296\n",
            "INFO:tensorflow:examples/sec: 973.558\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (27, 22)\n",
            "INFO:tensorflow:loss = 0.016601562, step = 274200 (27.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67761\n",
            "INFO:tensorflow:examples/sec: 941.468\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014404297, step = 274300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80282\n",
            "INFO:tensorflow:examples/sec: 973.522\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 47)\n",
            "INFO:tensorflow:loss = 0.016601562, step = 274400 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80269\n",
            "INFO:tensorflow:examples/sec: 973.489\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016845703, step = 274500 (26.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80257\n",
            "INFO:tensorflow:examples/sec: 973.459\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (31, 76)\n",
            "INFO:tensorflow:loss = 0.013916016, step = 274600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80305\n",
            "INFO:tensorflow:examples/sec: 973.581\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015258789, step = 274700 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80305\n",
            "INFO:tensorflow:examples/sec: 973.58\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014465332, step = 274800 (27.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67575\n",
            "INFO:tensorflow:examples/sec: 940.993\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (34, 1)\n",
            "INFO:tensorflow:loss = 0.017700195, step = 274900 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80283\n",
            "INFO:tensorflow:examples/sec: 973.524\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.013427734, step = 275000 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80304\n",
            "INFO:tensorflow:examples/sec: 973.579\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (36, 30)\n",
            "INFO:tensorflow:loss = 0.014953613, step = 275100 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80279\n",
            "INFO:tensorflow:examples/sec: 973.515\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017456055, step = 275200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80294\n",
            "INFO:tensorflow:examples/sec: 973.553\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (38, 55)\n",
            "INFO:tensorflow:loss = 0.01574707, step = 275300 (27.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66938\n",
            "INFO:tensorflow:examples/sec: 939.362\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0138549805, step = 275400 (26.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80257\n",
            "INFO:tensorflow:examples/sec: 973.457\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (40, 84)\n",
            "INFO:tensorflow:loss = 0.014709473, step = 275500 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80295\n",
            "INFO:tensorflow:examples/sec: 973.555\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014892578, step = 275600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80299\n",
            "INFO:tensorflow:examples/sec: 973.565\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015380859, step = 275700 (27.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67506\n",
            "INFO:tensorflow:examples/sec: 940.815\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (43, 9)\n",
            "INFO:tensorflow:loss = 0.012634277, step = 275800 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80297\n",
            "INFO:tensorflow:examples/sec: 973.559\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018920898, step = 275900 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80291\n",
            "INFO:tensorflow:examples/sec: 973.545\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (45, 38)\n",
            "INFO:tensorflow:loss = 0.01574707, step = 276000 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80277\n",
            "INFO:tensorflow:examples/sec: 973.508\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017700195, step = 276100 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80308\n",
            "INFO:tensorflow:examples/sec: 973.588\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (47, 67)\n",
            "INFO:tensorflow:loss = 0.016113281, step = 276200 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80316\n",
            "INFO:tensorflow:examples/sec: 973.608\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01373291, step = 276300 (27.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66839\n",
            "INFO:tensorflow:examples/sec: 939.109\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (49, 92)\n",
            "INFO:tensorflow:loss = 0.011474609, step = 276400 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80291\n",
            "INFO:tensorflow:examples/sec: 973.544\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.013000488, step = 276500 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8027\n",
            "INFO:tensorflow:examples/sec: 973.491\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 276500...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 276500 into gs://bucket_comment_completion/Matteo/HP_TUNING/ISR/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 276500...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (51, 92)\n",
            "INFO:tensorflow:loss = 0.011047363, step = 276600 (33.708 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.9667\n",
            "INFO:tensorflow:examples/sec: 759.474\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.012207031, step = 276700 (26.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8023\n",
            "INFO:tensorflow:examples/sec: 973.39\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.013916016, step = 276800 (27.551 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.62968\n",
            "INFO:tensorflow:examples/sec: 929.198\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (54, 16)\n",
            "INFO:tensorflow:loss = 0.013549805, step = 276900 (26.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80209\n",
            "INFO:tensorflow:examples/sec: 973.336\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.013366699, step = 277000 (26.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80212\n",
            "INFO:tensorflow:examples/sec: 973.344\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (56, 45)\n",
            "INFO:tensorflow:loss = 0.013183594, step = 277100 (26.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80207\n",
            "INFO:tensorflow:examples/sec: 973.329\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.012268066, step = 277200 (27.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67209\n",
            "INFO:tensorflow:examples/sec: 940.055\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (58, 70)\n",
            "INFO:tensorflow:loss = 0.012634277, step = 277300 (26.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80212\n",
            "INFO:tensorflow:examples/sec: 973.344\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014526367, step = 277400 (26.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8023\n",
            "INFO:tensorflow:examples/sec: 973.389\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (60, 99)\n",
            "INFO:tensorflow:loss = 0.014953613, step = 277500 (26.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80233\n",
            "INFO:tensorflow:examples/sec: 973.396\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014770508, step = 277600 (26.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80218\n",
            "INFO:tensorflow:examples/sec: 973.357\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015625, step = 277700 (26.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80224\n",
            "INFO:tensorflow:examples/sec: 973.373\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (63, 24)\n",
            "INFO:tensorflow:loss = 0.01361084, step = 277800 (27.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67094\n",
            "INFO:tensorflow:examples/sec: 939.761\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.012817383, step = 277900 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80253\n",
            "INFO:tensorflow:examples/sec: 973.448\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (65, 53)\n",
            "INFO:tensorflow:loss = 0.013671875, step = 278000 (26.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80248\n",
            "INFO:tensorflow:examples/sec: 973.434\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014709473, step = 278100 (26.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80214\n",
            "INFO:tensorflow:examples/sec: 973.348\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (67, 82)\n",
            "INFO:tensorflow:loss = 0.015136719, step = 278200 (26.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80226\n",
            "INFO:tensorflow:examples/sec: 973.379\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014160156, step = 278300 (28.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.45103\n",
            "INFO:tensorflow:examples/sec: 883.464\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014892578, step = 278400 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80271\n",
            "INFO:tensorflow:examples/sec: 973.493\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (70, 0)\n",
            "INFO:tensorflow:loss = 0.013427734, step = 278500 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80309\n",
            "INFO:tensorflow:examples/sec: 973.592\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.013427734, step = 278600 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80308\n",
            "INFO:tensorflow:examples/sec: 973.588\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (72, 29)\n",
            "INFO:tensorflow:loss = 0.0146484375, step = 278700 (27.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67823\n",
            "INFO:tensorflow:examples/sec: 941.627\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWWvPRKKJll3"
      },
      "source": [
        "### Evaluate the performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBXTPr0ke04I"
      },
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = 512\n",
        "model.eval(\n",
        "    mixture_or_task_name=\"all_tasks\",\n",
        "    # mixture_or_task_name=\"all_tasks\",\n",
        "    checkpoint_steps=-1 #evaluate only last checkpoint\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}