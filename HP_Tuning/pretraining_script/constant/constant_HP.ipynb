{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "constant_HP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k119Gm0VFG_y"
      },
      "source": [
        "### Configuration of the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h1MRzBLtex2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26310bf-fcb8-46ed-c2a0-993614877d1f"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip3 install --upgrade pip\n",
        "#!pip install -qU t5\n",
        "!pip3 install git+https://github.com/google-research/text-to-text-transfer-transformer.git #extra_id_x support\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "#Set the base dir(Google cloud bucket)\n",
        "BASE_DIR = \"gs://bucket_code_completion\" \n",
        "\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "\n",
        "if ON_CLOUD:\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/47/58b9f3e6f611dfd17fb8bd9ed3e6f93b7ee662fb85bdfee3565e8979ddf7/pip-21.0-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.0MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-21.0\n",
            "Collecting git+https://github.com/google-research/text-to-text-transfer-transformer.git\n",
            "  Cloning https://github.com/google-research/text-to-text-transfer-transformer.git to /tmp/pip-req-build-zrulez44\n",
            "  Running command git clone -q https://github.com/google-research/text-to-text-transfer-transformer.git /tmp/pip-req-build-zrulez44\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (0.10.0)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (2.9.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (0.4.0)\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "  Downloading mesh_tensorflow-0.1.18-py3-none-any.whl (361 kB)\n",
            "\u001b[K     |████████████████████████████████| 361 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (1.1.5)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (1.4.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14 in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (1.15.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.4.3-cp36-cp36m-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 12.7 MB/s \n",
            "\u001b[?25hCollecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.2.0.dev202101290106-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 64.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from t5==0.8.1) (1.7.0+cu101)\n",
            "Collecting transformers>=2.7.0\n",
            "  Downloading transformers-4.2.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 82.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (4.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 86.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (20.8)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
            "\u001b[K     |████████████████████████████████| 883 kB 84.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5==0.8.1) (0.8)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel->t5==0.8.1) (2018.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers>=2.7.0->t5==0.8.1) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers>=2.7.0->t5==0.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=2.7.0->t5==0.8.1) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->t5==0.8.1) (2.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.8.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.8.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.8.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.7.0->t5==0.8.1) (3.0.4)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.1.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.8.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.8.1) (1.0.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (20.3.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (2.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (0.1.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (0.27.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (5.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (0.3.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (51.3.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (1.52.0)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text->t5==0.8.1) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text->t5==0.8.1) (0.11.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.3.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.36.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (2.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.12)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (2.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.17.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (3.1.0)\n",
            "Building wheels for collected packages: t5, sacremoses\n",
            "  Building wheel for t5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for t5: filename=t5-0.8.1-py3-none-any.whl size=220069 sha256=d7c5ddf0186d9b0d510e9ff3799b01c85cd1d17bd0dcf9f53ab9b87baae574d0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fhbca93n/wheels/aa/e1/a1/847d16e451940b1fe89940aa88875c96ae2f7cc63e509e9226\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893258 sha256=c58626f9bb2dbabd764bcae6ae45d3a8a8625cf211e5c641609f5330eadc14fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
            "Successfully built t5 sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, portalocker, mesh-tensorflow, transformers, tfds-nightly, tensorflow-text, sentencepiece, sacrebleu, rouge-score, t5\n",
            "Successfully installed mesh-tensorflow-0.1.18 portalocker-2.1.0 rouge-score-0.0.4 sacrebleu-1.5.0 sacremoses-0.0.43 sentencepiece-0.1.95 t5-0.8.1 tensorflow-text-2.4.3 tfds-nightly-4.2.0.dev202101290106 tokenizers-0.9.4 transformers-4.2.2\n",
            "Running on TPU: grpc://10.84.84.90:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSiZxnN-FVZa"
      },
      "source": [
        "### Loading of the tsv files\n",
        "We loaded the 6 tsv files, please be sure to upload them on the bucket and to copy the correct path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glLJUm1dxIiH"
      },
      "source": [
        "#Validation(train and test on the same dataset)\n",
        "\n",
        "nq_tsv_path_java_construct = {\n",
        "    \"train\":      'gs://bucket_code_completion/T5_extension/ft_datasets/train_java_construct.tsv',\n",
        "    \"validation\": 'gs://bucket_code_completion/T5_extension/ft_datasets/eval_java_construct.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples_java_construct = dict(train=750000, validation=104037)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-B3_th9eP5y"
      },
      "source": [
        "#Validation(train and test on the same dataset)\n",
        "\n",
        "nq_tsv_path_android_construct = {\n",
        "    \"train\":      'gs://bucket_code_completion/T5_extension/ft_datasets/train_android_construct.tsv',\n",
        "    \"validation\": 'gs://bucket_code_completion/T5_extension/ft_datasets/eval_android_construct.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples_android_construct = dict(train=750000, validation=98793)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u7JbyjV8GN3"
      },
      "source": [
        "#Validation(train and test on the same dataset)\n",
        "\n",
        "nq_tsv_path_java_block = {\n",
        "    \"train\":      'gs://bucket_code_completion/T5_extension/ft_datasets/train_java_block.tsv',\n",
        "    \"validation\": 'gs://bucket_code_completion/T5_extension/ft_datasets/eval_java_block.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples_java_block = dict(train=298470, validation=38840)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmUMU-Pg8HVm"
      },
      "source": [
        "#Validation(train and test on the same dataset)\n",
        "\n",
        "nq_tsv_path_android_block = {\n",
        "    \"train\":      'gs://bucket_code_completion/T5_extension/ft_datasets/train_android_block.tsv',\n",
        "    \"validation\": 'gs://bucket_code_completion/T5_extension/ft_datasets/eval_android_block.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples_android_block = dict(train=204580, validation=26503)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5lRmNWG8HuD"
      },
      "source": [
        "#Validation(train and test on the same dataset)\n",
        "\n",
        "nq_tsv_path_java_token = {\n",
        "    \"train\":      'gs://bucket_code_completion/T5_extension/ft_datasets/train_java_token.tsv',\n",
        "    \"validation\": 'gs://bucket_code_completion/T5_extension/ft_datasets/eval_java_token.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples_java_token = dict(train=750000, validation=214682)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF9DHJxc8IGe"
      },
      "source": [
        "#Validation(train and test on the same dataset)\n",
        "\n",
        "nq_tsv_path_android_token = {\n",
        "    \"train\":      'gs://bucket_code_completion/T5_extension/ft_datasets/train_android_token.tsv',\n",
        "    \"validation\": 'gs://bucket_code_completion/T5_extension/ft_datasets/eval_android_token.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples_android_token = dict(train=750000, validation=198281)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pHAHde2FxF1"
      },
      "source": [
        "### Preprocess of the dataset\n",
        "In this step we preprocess the dataset.  \n",
        "You have to change the path to vocab files (*vocab_model_path* and *vocab_path*)\n",
        "We're going to preprocess all the tsv file so that T5 can use them for HP tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PobLvzL18zzR"
      },
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "vocab_model_path = 'gs://bucket_code_completion/T5_extension/code.model'\n",
        "vocab_path = 'gs://bucket_code_completion/T5_extension/code.vocab'\n",
        "\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn-DMH5FkSO2"
      },
      "source": [
        "JAVA CONSTRUCT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0NTLbyXvkCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adbda572-b2d2-4841-fd5b-4e9e9c202ed2"
      },
      "source": [
        "def nq_java_construct(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "   # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_java_construct[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(nq_java_construct(\"train\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw train examples...\n",
            "{'input': b'public void updateLockdownExceptions(ManagedObjectReference _this, String[] users) throws AuthMinimumAdminPermission, RemoteException, RuntimeFault, UserNotFound { Argument[] params = new Argument[2]; params[0] = new Argument(\"_this\", \"ManagedObjectReference\", _this); params[1] = new Argument(\"users\", \"String[]\", users); getWsc().invoke( <extra_id_0>); }', 'output': b'\"UpdateLockdownExceptions\", params, null'}\n",
            "{'input': b'@Override public Collection<AgentProjectInfo> collectDependencies(String folder) { if ( <extra_id_0>){ devDependencies = findDevDependencies(folder); } File yarnLock = new File(folder + fileSeparator + YARN_LOCK); boolean yarnLockFound = yarnLock.isFile(); Collection<DependencyInfo> dependencies = new ArrayList<>(); if (yarnLockFound){ dependencies = parseYarnLock(yarnLock); } else { npmLsFailureStatus = true; } return getSingleProjectList(dependencies); }', 'output': b'!includeDevDependencies'}\n",
            "{'input': b'@Override public Collection<AgentProjectInfo> collectDependencies(String folder) { if (!includeDevDependencies){ devDependencies = findDevDependencies(folder); } File yarnLock = new File(folder + fileSeparator + YARN_LOCK); boolean yarnLockFound = yarnLock.isFile(); Collection<DependencyInfo> dependencies = new ArrayList<>(); if ( <extra_id_0>){ dependencies = parseYarnLock(yarnLock); } else { npmLsFailureStatus = true; } return getSingleProjectList(dependencies); }', 'output': b'yarnLockFound'}\n",
            "{'input': b'@Override public Collection<AgentProjectInfo> collectDependencies(String folder) { if (!includeDevDependencies){ devDependencies = findDevDependencies(folder); } File yarnLock = new File( <extra_id_0>); boolean yarnLockFound = yarnLock.isFile(); Collection<DependencyInfo> dependencies = new ArrayList<>(); if (yarnLockFound){ dependencies = parseYarnLock(yarnLock); } else { npmLsFailureStatus = true; } return getSingleProjectList(dependencies); }', 'output': b'folder + fileSeparator + YARN_LOCK'}\n",
            "{'input': b'@Override public Collection<AgentProjectInfo> collectDependencies(String folder) { if (!includeDevDependencies){ devDependencies = findDevDependencies(folder); } File yarnLock = new File(folder + fileSeparator + YARN_LOCK); boolean yarnLockFound = yarnLock.isFile(); Collection<DependencyInfo> dependencies = new ArrayList<>(); if (yarnLockFound){ dependencies = parseYarnLock(yarnLock); } else { npmLsFailureStatus = true; } return getSingleProjectList( <extra_id_0>); }', 'output': b'dependencies'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bJZPQgjxKZ1"
      },
      "source": [
        "def java_construct_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['JAVA_CONSTRUCT:' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3jAg8Zhx_Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2d5156-6d9a-4e11-dc1d-aa34131ca4b8"
      },
      "source": [
        "t5.data.TaskRegistry.remove('java_construct')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"java_construct\",\n",
        "    dataset_fn=nq_java_construct,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[java_construct_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_java_construct\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f15ff87f710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e71p9JIFyYHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20cece22-1af0-43f8-ad65-739407a2c468"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"java_construct\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 256, \"targets\": 256})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'JAVA_CONSTRUCT:@Override public Object toJdbc(final Optional<?> original, final Connection connection, final BindParameterMapperManager parameterMapperManager) { return original.isPresent() ? parameterMapperManager.toJdbc( <extra_id_0>) : null; }', 'inputs': array([    3,  7641,    15,  5071, 17558,    56,  2098,    27,    12,\n",
            "         102,    81,  5537,     5,    64,   730,    25,     2,    29,\n",
            "        1302,     9,    44,  2097,   557,     9,    44,     3,  3003,\n",
            "         513,   898,   121,  1218,   898,   121,     8,     7,    14,\n",
            "        1302,     4,  2610,    16,     3,     2,  1218,   898,   121,\n",
            "           4,   314,  5537,     5, 32099,     8,    58,    30,    13,\n",
            "           6,     1], dtype=int32), 'targets_pretokenized': b'original.get(), connection', 'targets': array([1302,    4,   33,   72,  557,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_CONSTRUCT:private void cleanUpDynamicPackages() throws IOException{ for ( <extra_id_0>) { String serviceId = service.getId(); String packageLocation = inputData.workspaceDirectory + \"/\" + serviceId + \"/\" + StarterUtil.PACKAGE_DIR; File packageDir = new File(packageLocation); if(packageDir.exists() && packageDir.isDirectory()){ FileUtils.deleteDirectory(packageDir); log.log(Level.FINE, \"Deleted package directory for \" + serviceId + \" technology. : \" + packageLocation); } } }', 'inputs': array([    3,  7641,    15,  5071, 17558,    56,  8797,    20, 11102,\n",
            "        2431,  3809,    16,    42,   115,   683,    50,    17, 32099,\n",
            "           8,     7,    26, 12439,    11,   467,     4,   428,    18,\n",
            "          26,  2565,   331,    11,   297,    99,     4,  4484,   662,\n",
            "          34,  1573,    34, 12439,    34,  1573,    34,     3, 13130,\n",
            "         306,     4,  4224,    15,  3245,    13,   181,  2565,   490,\n",
            "          11,    24,   181,     5,  3703,   331,    10,    21,     5,\n",
            "        3703,   490,     4,  1090,    16,    91,  2565,   490,     4,\n",
            "        2875,  3023,  3321,     4,  7374,     5,  3703,   490,    10,\n",
            "         224,     4,   417,     5,   377,     4,  8498,     9,    32,\n",
            "        3030,  2565,  1364,    50,    32,    34, 12439,    34,    32,\n",
            "           3, 12866,     4,    58,    32,    34,  2565,   331,    10,\n",
            "           6,     6,     6,     1], dtype=int32), 'targets_pretokenized': b'Service service : inputData.services.getServices()', 'targets': array([   3,  108,  467,   58,  297,   99,    4, 6123,    4,   33, 1640,\n",
            "         16,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_CONSTRUCT:public static void writeSafeUTF (@Nonnull final DataOutput aDO, @Nullable final String sStr) throws IOException { ValueEnforcer.notNull (aDO, \"DataOutput\"); if (sStr == null) { aDO.writeByte (0); } else { aDO.writeByte ( <extra_id_0>); final byte [] aUTF8Bytes = sStr.getBytes (StandardCharsets.UTF_8); aDO.writeInt (aUTF8Bytes.length); aDO.write (aUTF8Bytes); aDO.writeInt (END_OF_STRING_MARKER); } }', 'inputs': array([    3,  7641,    15,  5071, 17558,    56,  4569,    48,    20,\n",
            "         412,  3012,  1227,     3,   261,   790,    44,     3,  6274,\n",
            "         107,  6383,     9,    19,   561,    44,    26,     3,    22,\n",
            "         910,     8,    42,   115,     7,     3,   106, 30104,     4,\n",
            "        2623,    17,   184,  6383,     9,    32,  6274,    46,    21,\n",
            "          17,    22,   910,    40,    30,     8,     7,   107,  6383,\n",
            "           4,  5091,     3,   659,     6,    77,     7,   107,  6383,\n",
            "           4,  5091,    17, 32099,    10,    44,   210,     3,    61,\n",
            "         107,  1227,     2,   571,    11,     3,    22,   910,     4,\n",
            "        1322,    17,  5303,     4,  1227,    15,     2,    10,   107,\n",
            "        6383,     4,  2213,    17,   184,  1227,     2,   571,     4,\n",
            "         105,    10,   107,  6383,     4,   371,    17,   184,  1227,\n",
            "           2,   571,    10,   107,  6383,     4,  2213,    17,  2636,\n",
            "          15,  2201,    15,  1885,    15, 11152,    10,     6,     6,\n",
            "           1], dtype=int32), 'targets_pretokenized': b'2', 'targets': array([804,   1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_CONSTRUCT:private SearchControls getDefaultSearchControls(int searchScope, boolean returningObjFlag, String[] attrs) { SearchControls controls = new SearchControls(); controls.setSearchScope(searchScope); controls.setTimeLimit(defaultTimeLimit); controls.setCountLimit(defaultCountLimit); controls.setReturningObjFlag(returningObjFlag); controls.setReturningAttributes( <extra_id_0>); return controls; }', 'inputs': array([    3,  7641,    15,  5071, 17558,    56,  8797,  3601,  4542,\n",
            "        1651,   758,  4542,     5,    53,  1014,   997,     9,    45,\n",
            "          14,   150,  1226,  1362,     9,    26,    61,  1085,     8,\n",
            "           7,  3601,  4542, 12305,    11,    24,  3601,  4542,    18,\n",
            "       12305,     4,    63, 21025,     5,  1508,   997,    10, 12305,\n",
            "           4,  4932,  1159,     5,   874,   199,  1159,    10, 12305,\n",
            "           4,    63,   182,  1159,     5,   874,   182,  1159,    10,\n",
            "       12305,     4,    63, 12990,  1226,  1362,     5,  1583,   150,\n",
            "        1226,  1362,    10, 12305,     4,    63, 12990,   743,     5,\n",
            "       32099,    10,    14, 12305,    13,     6,     1], dtype=int32), 'targets_pretokenized': b'attrs', 'targets': array([1085,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_CONSTRUCT:private void poolForFiles(long minTimeStamp, String currentBlobGeneratedId, String currentFileOffset) { Page<Blob> blobs = storage.list( gcsOriginConfig.bucketTemplate, Storage.BlobListOption.prefix(GcsUtil.normalizePrefix(gcsOriginConfig.commonPrefix)) ); blobs.iterateAll().forEach(blob -> { if (isBlobEligible(blob, minTimeStamp, currentBlobGeneratedId, currentFileOffset)) { minMaxPriorityQueue.add( <extra_id_0>); } }); }', 'inputs': array([    3,  7641,    15,  5071, 17558,    56,  8797,    20,  1948,\n",
            "         203,   778,     5,   288,   700,  6513,     9,    26,   337,\n",
            "        2774,  4527,    68,     9,    26,   337,   104,   553,     8,\n",
            "           7,  3031,    25,  2774,    29,  6148,    22,    11,  1840,\n",
            "           4,   430,     5, 21996,  2884,   151,     4,  4296,   577,\n",
            "           9,  5976,     4,  2774,    71,   721,     4,  1603,     5,\n",
            "        8590,    22,   306,     4,  5368,   766,     5,  5323,    22,\n",
            "        2884,   151,     4,  4146,   766,     8,     8,     3,    10,\n",
            "        6148,    22,     4, 25510,   517,    37,  1781,     5,  9475,\n",
            "         332,     7,    21,    17,   112,  2774, 28749,     5,  9475,\n",
            "           9,   700,  6513,     9,   337,  2774,  4527,    68,     9,\n",
            "         337,   104,   553,     8,     8,     7,   700,  1005,  2452,\n",
            "           2,   514,     4,    67,     5, 32099,    10,     6,     6,\n",
            "          10,     6,     1], dtype=int32), 'targets_pretokenized': b'blob', 'targets': array([6148,    1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB-KY403kcCn"
      },
      "source": [
        "JAVA TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNi7HPiOz27q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d36156-498d-43b5-e282-0904f7c62e9e"
      },
      "source": [
        "def nq_java_token(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_java_token[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw valid examples...\")\n",
        "for ex in tfds.as_numpy(nq_java_token(\"validation\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw valid examples...\n",
            "{'input': b'public void addThirdPartyPaymentWorkflow(com.mozu.api.contracts.sitesettings.order.ExternalPaymentWorkflowDefinition definition) throws Exception { MozuClient client = com.mozu.api.clients.commerce.settings.checkout.PaymentSettingsClient <extra_id_0> client.setContext(_apiContext); client.executeRequest(); client.cleanupHttpConnection(); }', 'output': b'.addThirdPartyPaymentWorkflowClient( definition);'}\n",
            "{'input': b'public void addThirdPartyPaymentWorkflow(com.mozu.api.contracts.sitesettings.order.ExternalPaymentWorkflowDefinition definition) throws Exception { MozuClient client = com.mozu.api.clients.commerce.settings.checkout.PaymentSettingsClient.addThirdPartyPaymentWorkflowClient( definition); client.setContext(_apiContext <extra_id_0> client.executeRequest(); client.cleanupHttpConnection(); }', 'output': b');'}\n",
            "{'input': b'public void addThirdPartyPaymentWorkflow(com.mozu.api.contracts.sitesettings.order.ExternalPaymentWorkflowDefinition definition) throws Exception { MozuClient client = com.mozu.api.clients.commerce.settings.checkout.PaymentSettingsClient.addThirdPartyPaymentWorkflowClient( definition); client.setContext(_apiContext); client <extra_id_0> client.cleanupHttpConnection(); }', 'output': b'.executeRequest();'}\n",
            "{'input': b'public void addThirdPartyPaymentWorkflow(com.mozu.api.contracts.sitesettings.order.ExternalPaymentWorkflowDefinition definition) throws Exception { MozuClient client = com.mozu.api.clients.commerce.settings.checkout.PaymentSettingsClient.addThirdPartyPaymentWorkflowClient( definition); client.setContext(_apiContext); client.executeRequest(); client.cleanupHttpConnection <extra_id_0> }', 'output': b'();'}\n",
            "{'input': b'protected Map<String, List<MigratingVariableInstance>> getMigratingVariableInstancesByName(MigratingActivityInstance activityInstance) { Map<String, List<MigratingVariableInstance>> result = new HashMap<String, List<MigratingVariableInstance <extra_id_0> for (MigratingInstance migratingInstance : activityInstance.getMigratingDependentInstances()) { if (migratingInstance instanceof MigratingVariableInstance) { MigratingVariableInstance migratingVariableInstance = (MigratingVariableInstance) migratingInstance; CollectionUtil.addToMapOfLists(result, migratingVariableInstance.getVariableName(), migratingVariableInstance); } } return result; }', 'output': b'>>();'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvDAbgNY0B4Y"
      },
      "source": [
        "def java_token_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['JAVA_TOKEN:' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mm6AQfw0INC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf91f3b-bf81-42b1-8132-5ab80dd8c3df"
      },
      "source": [
        "t5.data.TaskRegistry.remove('java_token')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"java_token\",\n",
        "    dataset_fn=nq_java_token,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[java_token_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_java_token\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f15ff7fb470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnf25qt10Wkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "322d0fe0-c115-4c4b-c393-9d8edb58507d"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"java_token\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 256, \"targets\": 256})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'JAVA_TOKEN:public static void addMessage(String bundleBaseName, FacesMessage.Severity severity, String messageId, Object[] args, String forClientId, FacesContext facesContext) { if(log.isLoggable(Level.FINEST <extra_id_0> { log.finest(\"adding message \" + messageId + \" for clientId \" + forClientId); } facesContext.addMessage(forClientId, getMessage(bundleBaseName, severity, messageId, args, facesContext)); }', 'inputs': array([    3,  7641,    15,  2591,    56,  4569,    48,    20,     3,\n",
            "        9341,     5,    31,  1405,   431,    66,     9,     3, 12563,\n",
            "         155,     4,  5015,  8007,     9,    26,  7862,     9,   102,\n",
            "          61,   294,     9,    26,    50, 10414,     9,     3, 10003,\n",
            "           3, 23090,     8,     7,    21,     5,   417,     4,  7417,\n",
            "           5,   377,     4, 24151, 32099,     7,   224,     4, 18887,\n",
            "          28,    67,   150,   175,    32,    34,  7862,    34,    32,\n",
            "          50,  4938,    32,    34,    50, 10414,    10,     6,     3,\n",
            "       23090,     4,  9341,     5,  1943, 10414,     9,     3,   429,\n",
            "           5,  2650,   431,    66,     9,  8007,     9,  7862,     9,\n",
            "         294,     9,     3, 23090,    79,     6,     1], dtype=int32), 'targets_pretokenized': b'))', 'targets': array([3, 8, 8, 1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_TOKEN:private Expression generateSingleMsgVariable(MsgNode msgNode, String tmpVarName) { String googMsgVarName = buildGoogMsgVarNameHelper(msgNode); GoogMsgCodeGenInfo googMsgCodeGenInfo = genGoogGetMsgCallHelper(googMsgVarName, msgNode); if (!msgNode.isPlrselMsg()) { return googMsgCodeGenInfo.googMsgVar; } return VariableDeclaration.builder(tmpVarName) .setRhs <extra_id_0> .build() .ref(); }', 'inputs': array([    3,  7641,    15,  2591,    56,  8797,  2072,   908,  1623,\n",
            "        1253,   866,     5,  1253,   152,   454,   152,     9,    26,\n",
            "        1723, 14515,     8,     7,    26,  4801, 11385,  1253, 14515,\n",
            "          11,   501,  7989, 11385,  1253, 14515,   327,     5,   744,\n",
            "         152,    10, 13106, 11385,  1253, 27316,   137,  4801, 11385,\n",
            "        1253, 27316,   137,    11,  4016,  7989, 11385,   749,  1253,\n",
            "         483,   327,     5,  4743, 11385,  1253, 14515,     9,   454,\n",
            "         152,    10,    21,   124,   744,   152,     4,   112,   364,\n",
            "        8759, 11616,  1253,    60,     7,    14,  4801, 11385,  1253,\n",
            "       27316,   137,     4,  4743, 11385,  1253,  1692,    13,     6,\n",
            "          14,  4672,  1199,     4,   534,     5,  2661, 14515,     8,\n",
            "           3,     4,    63,   144, 11712, 32099,     3,     4,   352,\n",
            "          16,     3,     4,  1391,    18,     6,     1], dtype=int32), 'targets_pretokenized': b'(getMessageFormatCall(googMsgCodeGenInfo))', 'targets': array([   17,   429,   495,   483,     5,  4743, 11385,  1253, 27316,\n",
            "         137,     8,     8,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_TOKEN:public void enableSSL <extra_id_0> SSLSocketFactory factory = context.getSocketFactory(); con = factory.createSocket(con, con.getInetAddress().getHostAddress(), con.getPort(), true); ((SSLSocket)con).setUseClientMode(false); reader = new BufferedReader(new InputStreamReader(con.getInputStream())); writer = new BufferedWriter(new OutputStreamWriter(con.getOutputStream())); }', 'inputs': array([    3,  7641,    15,  2591,    56,  4569,    20,  1526,  4815,\n",
            "       32099,     3, 16983,  1081,    11,   130,     4,    33,  9569,\n",
            "          18,  2059,    11,  1081,     4, 14285,     5,  3081,     9,\n",
            "        2059,     4,    33,  6069,    37, 13511,    72,  2059,     4,\n",
            "        4662,    72,    89,    10,    17,     5, 21272,     8,  3081,\n",
            "           8,     4, 10154,   229,   270,     5,   348,    10,   931,\n",
            "          11,    24,  2827,     5,    74,   956,   426,     5,  3081,\n",
            "           4,  4481,   366,   688,    11,    24,  9059,     5,    74,\n",
            "        2611,   567,     5,  3081,     4,  6357,   366,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'(SSLContext context) throws IOException {', 'targets': array([   17, 16946,   130,     8,    42,   115,     7,     1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_TOKEN:public static DoubleMatrix cholesky(DoubleMatrix A) { DoubleMatrix result = A.dup(); int info = NativeBlas.dpotrf(\\'U\\', A.rows, result.data, 0, A.rows); if (info < 0) { throw new LapackArgumentException(\"DPOTRF\", -info); } else if (info > 0) { throw new LapackPositivityException(\"DPOTRF\", \"Minor \" + info + \" was negative. Matrix must be positive definite.\"); } clearLower <extra_id_0> return result; }', 'inputs': array([    3,  7641,    15,  2591,    56,  4569,    48,   817,  1595,\n",
            "         202, 16693, 18200,     5,   759,  1595,  1283,     8,     7,\n",
            "         817,  1595,    84,    11,  1283,     4, 18380,    18,    35,\n",
            "         657,    11,  8831,   285,  3208,    22,     4,   101,  9576,\n",
            "       11613,     5,     2,  1094,     2,     9,  1283,     4,  4538,\n",
            "           9,    84,     4,   258,     9,   312,  1283,     4,  4538,\n",
            "          10,    21,    17,   274,   136,   178,     7,    78,    24,\n",
            "           3, 18992,  8037,  1384,    38,    28,  7829, 11120,  9722,\n",
            "          43,   139,   274,    10,     6,    77,    21,    17,   274,\n",
            "           3,    29,   178,     7,    78,    24,     3, 18992,  8037,\n",
            "         785,  1256, 11667,    38,    28,  7829, 11120,  9722,    43,\n",
            "          32,  8170,    32,    34,   657,    34,    32,   945,  6569,\n",
            "           4,  3563,   848,   198,  7225,  2424, 22292,     4,    46,\n",
            "           6,   919,  6945, 32099,    14,    84,    13,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'(result);', 'targets': array([ 17, 360,  10,   1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_TOKEN:public static long getTimeOfTheName(String fileName) throws NumberFormatException{ String longStr = fileName.substring(0, fileName.length() - 3); Long lo = Long.parseLong(longStr); return <extra_id_0> }', 'inputs': array([    3,  7641,    15,  2591,    56,  4569,    48,   126,  7743,\n",
            "       18799,    66,     5,    31,  1299,     8,    42,  7487,    38,\n",
            "         683,    26,   126,   910,    11,  1299,     4,   633,   537,\n",
            "        1299,     4,   105,    16,   139,     3,     2,    10,   493,\n",
            "       13419,    11,   493,     4,  4306,     5,   288,   910,    10,\n",
            "          14, 32099,     6,     1], dtype=int32), 'targets_pretokenized': b'lo;', 'targets': array([13419,    13,     1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIe-u5l9ke6x"
      },
      "source": [
        "JAVA BLOCK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr0TT18ejMtY",
        "outputId": "5b56624b-ec14-4ea0-94ea-868cc259d7ed"
      },
      "source": [
        "def nq_java_block(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_java_block[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw valid examples...\")\n",
        "for ex in tfds.as_numpy(nq_java_block(\"validation\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw valid examples...\n",
            "{'input': b'public Object createField(String name) { Object reader = _fieldMap.get(name); if (reader == null) <extra_id_0> return reader; }', 'output': b'reader = NullFieldDeserializer.DESER;'}\n",
            "{'input': b'@Nonnull public static JSInvocation invoke (@Nonnull final JQueryInvocation aJQueryInvocation, @Nonnull final JSAssocArray aOptions) <extra_id_0>', 'output': b'{ return invoke (aJQueryInvocation).arg (aOptions); }'}\n",
            "{'input': b'public static String presentMinMaxCount(long minmax) { if (minmax == Long.MAX_VALUE || minmax == Long.MIN_VALUE) <extra_id_0> return String.valueOf(minmax); }', 'output': b'{ return UNDEF_STRING; }'}\n",
            "{'input': b'@Override public NonBottomTypeNode<ElkClass, ElkNamedIndividual> getCreateNode( final Collection<? extends ElkClass> members) <extra_id_0>', 'output': b'{ return getCreateUpdateableTypeNode( classTaxonomy_.getCreateNode(members)); }'}\n",
            "{'input': b'public static JsonException typeMismatch(Object indexOrName, Object actual, String requiredType, boolean mode) throws JsonException { if (actual == null) <extra_id_0> else { throw new JsonException(\"Value \" + actual + \" at \" + indexOrName + \" of type \" + actual.getClass().getName() + \" cannot be converted to \" + requiredType + \". Strict mode is: \" + mode); } }', 'output': b'{ throw new JsonException(\"Value at \" + indexOrName + \" is null.\"); }'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq0uLYNTjM9z"
      },
      "source": [
        "def java_block_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['JAVA_BLOCK:' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji4u8yhqjNER",
        "outputId": "92b0a218-732d-40ca-b08c-ee52295d5ec6"
      },
      "source": [
        "t5.data.TaskRegistry.remove('java_block')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"java_block\",\n",
        "    dataset_fn=nq_java_block,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[java_block_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_java_block\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f15ff834f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG09lDZdjNKr",
        "outputId": "f943ba9f-b5fd-4720-8984-c003083e1329"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"java_block\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 256, \"targets\": 256})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'JAVA_BLOCK:public Repository getRepository(String uid, Integer maxUsers) throws GreenPepperServerException { try { sessionService.startSession(); Repository repository = loadRepository(uid); if (maxUsers != null) { repository.setMaxUsers(maxUsers); } return repository; } finally <extra_id_0> }', 'inputs': array([    3,  7641,    15,  3517,    56,  4569,  2522, 11250,     5,\n",
            "          31,  4103,     9,   237,   350,  2178,     8,    42,     3,\n",
            "       11541,   364,  4384,  3238, 12598,     7,    93,     7,   509,\n",
            "         108,     4,   373,   413,    18,  2522,  1576,    11,   551,\n",
            "         458,     5,  3477,    10,    21,    17,   532,  2178,    49,\n",
            "          30,     8,     7,  1576,     4,  5690,  2178,     5,   532,\n",
            "        2178,    10,     6,    14,  1576,    13,     6,   658, 32099,\n",
            "           6,     1], dtype=int32), 'targets_pretokenized': b'{ sessionService.closeSession(); }', 'targets': array([  7, 509, 108,   4, 363, 413,  18,   6,   1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_BLOCK:@Override public Long expire(String key, int seconds) { Long result = redisString.expire(key, seconds); if (result == 0) <extra_id_0> return result; }', 'inputs': array([    3,  7641,    15,  3517,    56,  2098,    27,    12,   493,\n",
            "       13503,     5,    31,   145,     9,    35,  3968,     8,     7,\n",
            "         493,    84,    11,     3, 10743,    31,     4, 16358,     5,\n",
            "         158,     9,  3968,    10,    21,    17,   360,    40,   178,\n",
            "       32099,    14,    84,    13,     6,     1], dtype=int32), 'targets_pretokenized': b'{ }', 'targets': array([7, 6, 1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_BLOCK:private PasswordBasedCipherFactory getPBEFactory(String hint) { try <extra_id_0> catch (ComponentLookupException e) { throw new UnsupportedOperationException(\"Password based cipher factory not found: \" + hint, e); } }', 'inputs': array([    3,  7641,    15,  3517,    56,  8797,     3,   962,  2992,\n",
            "        4346,   149,  7569,  6217,   149,     5,    31,  8911,     8,\n",
            "           7,    93, 32099,    97,    17,   405,  1652,    38,    57,\n",
            "           8,     7,    78,    24,     3,   751,   735,    28,   962,\n",
            "        6142,  5641,  1081,   153,   807,    56,    32,    34,  8911,\n",
            "           9,    57,    10,     6,     6,     1], dtype=int32), 'targets_pretokenized': b'{ return this.manager.getInstance(PasswordBasedCipherFactory.class, hint); }', 'targets': array([   7,   14,   23,    4, 2515,    4,  351,    5,  962, 2992, 4346,\n",
            "        149,    4,   88,    9, 8911,   10,    6,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_BLOCK:private Set<String> getJSHeadIncludes(CmsObject cms, CmsResource resource) throws CmsLoaderException { I_CmsResourceType resType = OpenCms.getResourceManager().getResourceType(resource.getTypeId()); if (resType instanceof CmsResourceTypeXmlContent) { try { CmsXmlContentDefinition contentDefinition = CmsXmlContentDefinition.getContentDefinitionForResource( cms, resource); return contentDefinition.getContentHandler().getJSHeadIncludes(cms, resource); } catch (CmsException e) <extra_id_0> } return Collections.emptySet(); }', 'inputs': array([    3,  7641,    15,  3517,    56,  8797,   300,    25,    31,\n",
            "          29,    41,  4174,  3058, 17813,     5, 24485,     3,  9643,\n",
            "           9,  4262,   256,   623,     8,    42,  4262,   856,    38,\n",
            "           7,   266,    15,  5065,  7780,   680,    51,    11, 28856,\n",
            "           4,    33,  9313,    37, 22532,     5,  1050,     4,   639,\n",
            "          68,    39,    21,    17,  1551,    51,   166,  4262,  7780,\n",
            "           2,   741,   399,     8,     7,    93,     7,  4262,     2,\n",
            "         741,   399,   530,   666,   530,    11,  4262,     2,   741,\n",
            "         399,   530,     4,  3204,   530,   203,   256,     5,     3,\n",
            "        9643,     9,   623,    10,    14,   666,   530,     4,    33,\n",
            "       10787,    37,    33,  4174,  3058, 17813,     5,  9643,     9,\n",
            "         623,    10,     6,    97,    17,  5065,    38,    57,     8,\n",
            "       32099,     6,    14,   665,     4,  7622,    18,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'{ LOG.warn(e.getLocalizedMessage(), e); }', 'targets': array([   7,  678,    4,  999,    5,  110,    4,   33, 8145,   72,   57,\n",
            "         10,    6,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'JAVA_BLOCK:@VisibleForTesting static String createNormalizedInternedPathname(String dir1, String dir2, String fname) { String pathname = dir1 + File.separator + dir2 + File.separator + fname; Matcher m = MULTIPLE_SEPARATORS.matcher(pathname); pathname = m.replaceAll(\"/\"); if (pathname.length() > 1 && pathname.endsWith(\"/\")) <extra_id_0> return pathname.intern(); }', 'inputs': array([    3,  7641,    15,  3517,    56,  2098,  4580,   150,    48,\n",
            "          26,   131,  6467, 24767,   159,   128,    98,     5,    31,\n",
            "        1337,   329,    26,  1337,   643,    26, 20577,     8,     7,\n",
            "          26, 16998,    11,  1337,    94,    34,   181,     4,  2381,\n",
            "          34,  1337,    80,    34,   181,     4,  2381,    34, 20577,\n",
            "          13,  2908,    54,    11,     3, 22381,    15,  3523,   113,\n",
            "           4,  1311,     5,   330,    98,    10, 16998,    11,    54,\n",
            "           4,  1848,  1100,    46,    21,    17,   330,    98,     4,\n",
            "         105,    16,     3,    29,   279,    91, 16998,     4,  1701,\n",
            "        7382, 32099,    14, 16998,     4,  9754,    18,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'{ pathname = pathname.substring(0, pathname.length() - 1); }', 'targets': array([    7, 16998,    11, 16998,     4,   633,   537, 16998,     4,\n",
            "         105,    16,   139,   581,     6,     1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz_Gxq_4khQt"
      },
      "source": [
        "ANDROID CONSTRUCT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNwnQAMVjNdy",
        "outputId": "55e01112-3835-467b-ad6d-4b5bc2804aab"
      },
      "source": [
        "def nq_android_construct(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "   # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_android_construct[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(nq_android_construct(\"train\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw train examples...\n",
            "{'input': b'private void writeToFile(final String content) { if ( <extra_id_0>) { return; } try { System.err.println(content); File f = new File(OUTPUT_FILE); f.delete(); FileWriter fstream = new FileWriter(OUTPUT_FILE); BufferedWriter out = new BufferedWriter(fstream); out.write(content); out.close(); } catch (Exception e) { e.printStackTrace(); } }', 'output': b'!WRITE_TO_FILE'}\n",
            "{'input': b'private void writeToFile(final String content) { if (!WRITE_TO_FILE) { return; } try { System.err.println(content); File f = new File(OUTPUT_FILE); f.delete(); FileWriter fstream = new FileWriter(OUTPUT_FILE); BufferedWriter out = new BufferedWriter(fstream); out.write(content); out.close(); } catch ( <extra_id_0>) { e.printStackTrace(); } }', 'output': b'Exception e'}\n",
            "{'input': b'private void writeToFile(final String content) { if (!WRITE_TO_FILE) { return; } try { System.err.println(content); File f = new File( <extra_id_0>); f.delete(); FileWriter fstream = new FileWriter(OUTPUT_FILE); BufferedWriter out = new BufferedWriter(fstream); out.write(content); out.close(); } catch (Exception e) { e.printStackTrace(); } }', 'output': b'OUTPUT_FILE'}\n",
            "{'input': b'private void writeToFile(final String content) { if (!WRITE_TO_FILE) { return; } try { System.err.println( <extra_id_0>); File f = new File(OUTPUT_FILE); f.delete(); FileWriter fstream = new FileWriter(OUTPUT_FILE); BufferedWriter out = new BufferedWriter(fstream); out.write(content); out.close(); } catch (Exception e) { e.printStackTrace(); } }', 'output': b'content'}\n",
            "{'input': b'private void writeToFile(final String content) { if (!WRITE_TO_FILE) { return; } try { System.err.println(content); File f = new File(OUTPUT_FILE); f.delete(); FileWriter fstream = new FileWriter(OUTPUT_FILE); BufferedWriter out = new BufferedWriter(fstream); out.write( <extra_id_0>); out.close(); } catch (Exception e) { e.printStackTrace(); } }', 'output': b'content'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sBEViP5jNja"
      },
      "source": [
        "def android_construct_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['ANDROID_CONSTRUCT:' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP_VXjC6jNpp",
        "outputId": "42f395a7-cc55-49c1-c965-e3a30b8b9505"
      },
      "source": [
        "t5.data.TaskRegistry.remove('android_construct')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"android_construct\",\n",
        "    dataset_fn=nq_android_construct,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[android_construct_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_android_construct\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f15ff60ee80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOWFYL7KjNwd",
        "outputId": "4c1ef2cb-57d5-407e-fb31-f2aa5338255e"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"android_construct\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 256, \"targets\": 256})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'ANDROID_CONSTRUCT:public void onTimeSet(TimePicker view, int hourOfDay, int minute) { editor = prefs.edit(); Log.i(\"CfDC\", \"Hour: \" + hourOfDay + \" Minute: \" + minute); editor.putInt( <extra_id_0>); editor.putInt(baseExtensionSettings.getPrefTimeMinute(), minute); editor.commit(); }', 'inputs': array([    3, 16446,    15,  5071, 17558,    56,  4569,    20,   170,\n",
            "         199,   174,     5, 20635,   403,     9,    35, 26952,     9,\n",
            "          35,  8569,     8,     7,  1424,    11,  2344,     4,  1769,\n",
            "          18,   319,     4,    86,    28,   302,   165,  5691,    43,\n",
            "          32,  5705,    56,    32,    34, 26952,    34,    32,     3,\n",
            "        7130,    56,    32,    34,  8569,    10,  1424,     4,  2870,\n",
            "           5, 32099,    10,  1424,     4,  2870,     5,  1015,   867,\n",
            "         460,     4,    33,  2503,   199,  7130,    72,  8569,    10,\n",
            "        1424,     4,  1827,    18,     6,     1], dtype=int32), 'targets_pretokenized': b'baseExtensionSettings.getPrefTimeHour(), hourOfDay', 'targets': array([  725,   867,   460,     4,    33,  2503,   199,  5705,    72,\n",
            "       26952,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_CONSTRUCT:public static int getResourceFromCode(String code) { Integer resId = null; if (!code.isEmpty()) { code = code.substring(0, Math.min(code.length(), 3)).toLowerCase(); resId = flagsMap.get(code); if (resId == null) { resId = flagsMap.get( <extra_id_0>); } } return resId == null ? R.drawable.unknown : resId; }', 'inputs': array([    3, 16446,    15,  5071, 17558,    56,  4569,    48,    35,\n",
            "        4885,   253,   359,     5,    31,   732,     8,     7,   237,\n",
            "        9047,    11,    30,    13,    21,   124,   830,     4,   280,\n",
            "          60,     7,   732,    11,   732,     4,   633,   537,   608,\n",
            "           4,   769,     5,   830,     4,   105,    72,     3,     2,\n",
            "           8,     8,     4,  1111,    18,  9047,    11,  1936,   100,\n",
            "           4,    33,     5,   830,    10,    21,    17, 12816,    40,\n",
            "          30,     8,     7,  9047,    11,  1936,   100,     4,    33,\n",
            "           5, 32099,    10,     6,     6,    14,  9047,    40,    30,\n",
            "           3,     2,   544,     4,  2471,     4,  5126,    58,  9047,\n",
            "          13,     6,     1], dtype=int32), 'targets_pretokenized': b'code.substring(0, 2)', 'targets': array([ 732,    4,  633,  537, 2068,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_CONSTRUCT:public boolean inRange(Calendar time) { time = fixDate(time); if (start.equals( <extra_id_0>) ) { return true; } else if (end.before(start)){ return ( time.after(start) || time.before(end) ); } else if (! start.equals(end)) { return ( time.after(start) && time.before(end) ); } return true; }', 'inputs': array([    3, 16446,    15,  5071, 17558,    56,  4569,    45,   140,\n",
            "         594,     5,   940,   546,     8,     7,   546,    11,  2477,\n",
            "         267,     5,   918,    10,    21,    17,   373,     4,   117,\n",
            "           5, 32099,     8,     3,     8,     7,    14,    89,    13,\n",
            "           6,    77,    21,    17,   852,     4,  3694,     5,   373,\n",
            "        3995,    14,    17,   546,     4,  3428,     5,   373,     8,\n",
            "           3,     2,   546,     4,  3694,     5,   852,     8,     3,\n",
            "          10,     6,    77,    21,   124,   241,     4,   117,     5,\n",
            "         852,     8,     8,     7,    14,    17,   546,     4,  3428,\n",
            "           5,   373,     8,    91,   546,     4,  3694,     5,   852,\n",
            "           8,     3,    10,     6,    14,    89,    13,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'time', 'targets': array([546,   1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_CONSTRUCT:protected Integer doInBackground(Void... params) { try { PlaintextBackupImporter.importPlaintextFromSd(getActivity(), masterSecret); return SUCCESS; } catch (NoExternalStorageException e) { Log.w( <extra_id_0>); return NO_SD_CARD; } catch (IOException e) { Log.w(\"ImportFragment\", e); return ERROR_IO; } }', 'inputs': array([    3, 16446,    15,  5071, 17558,    56, 18728,   237,  7088,\n",
            "           5,  1870,     4,     4,     4,   469,     8,     7,    93,\n",
            "           7,     3, 24497,  2780,  6818,     4,  3168, 24497,   253,\n",
            "         113,   101,     5,  1926,    72,     3, 18473,    10,    14,\n",
            "           3,  3069,    13,     6,    97,    17,   496, 16407,    38,\n",
            "          57,     8,     7,   319,     4,   550,     5, 32099,    10,\n",
            "          14,  6022,    15,  4053,    15, 10416,    13,     6,    97,\n",
            "          17,   487,    57,     8,     7,   319,     4,   550,    28,\n",
            "        1421,   619,    43,    57,    10,    14,     3,  1024,    15,\n",
            "        2026,    13,     6,     6,     1], dtype=int32), 'targets_pretokenized': b'\"ImportFragment\", e', 'targets': array([  32, 1421,  619,   43,   57,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_CONSTRUCT:private void setLogState(LogState newState) { switch (newState) { case FULL: svELogCont.setVisibility(View.GONE); svLogCont.setVisibility( <extra_id_0>); break; case ERRORS: svLogCont.setVisibility(View.GONE); svELogCont.setVisibility(View.VISIBLE); break; } }', 'inputs': array([    3, 16446,    15,  5071, 17558,    56,  8797,    20, 18610,\n",
            "         119,     5,   477,   119,  7861,     8,     7,   695,    17,\n",
            "          74,   119,     8,     7,   234,     3,  5996,    56, 12790,\n",
            "         146,   477, 18402,     4,  1549,     5,   143,     4,  2932,\n",
            "          10, 12790,   477, 18402,     4,  1549,     5, 32099,    10,\n",
            "         591,    13,   234,     3,  1024,   113,    56, 12790,   477,\n",
            "       18402,     4,  1549,     5,   143,     4,  2932,    10, 12790,\n",
            "         146,   477, 18402,     4,  1549,     5,   143,     4,  2314,\n",
            "          10,   591,    13,     6,     6,     1], dtype=int32), 'targets_pretokenized': b'View.VISIBLE', 'targets': array([ 886,    4, 2314,    1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ9H1D-KngJy"
      },
      "source": [
        "ANDROID TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgi_2yd-nb4Y",
        "outputId": "38268f6c-acca-4499-c1f0-7840c80fd84a"
      },
      "source": [
        "def nq_android_token(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_android_token[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw valid examples...\")\n",
        "for ex in tfds.as_numpy(nq_android_token(\"validation\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw valid examples...\n",
            "{'input': b'public void register(Context context <extra_id_0> IntentFilter intentFilter = buildFilter(); try { register(context, intentFilter); }catch (IllegalArgumentException e){ Log.w(TAG, \"Error registering receiver. Receiver maybe already registered, unregistering to register again.\"); unregister(context); register(context, intentFilter); } }', 'output': b') {'}\n",
            "{'input': b'public void register(Context context) { IntentFilter intentFilter <extra_id_0> try { register(context, intentFilter); }catch (IllegalArgumentException e){ Log.w(TAG, \"Error registering receiver. Receiver maybe already registered, unregistering to register again.\"); unregister(context); register(context, intentFilter); } }', 'output': b'= buildFilter();'}\n",
            "{'input': b'public void register(Context context) { IntentFilter intentFilter = buildFilter(); try <extra_id_0> register(context, intentFilter); }catch (IllegalArgumentException e){ Log.w(TAG, \"Error registering receiver. Receiver maybe already registered, unregistering to register again.\"); unregister(context); register(context, intentFilter); } }', 'output': b'{'}\n",
            "{'input': b'public void register(Context context) { IntentFilter intentFilter = buildFilter(); try { register(context, intentFilter <extra_id_0> }catch (IllegalArgumentException e){ Log.w(TAG, \"Error registering receiver. Receiver maybe already registered, unregistering to register again.\"); unregister(context); register(context, intentFilter); } }', 'output': b');'}\n",
            "{'input': b'public void register(Context context) { IntentFilter intentFilter = buildFilter(); try { register(context, intentFilter); }catch (IllegalArgumentException <extra_id_0> Log.w(TAG, \"Error registering receiver. Receiver maybe already registered, unregistering to register again.\"); unregister(context); register(context, intentFilter); } }', 'output': b'e){'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcKSDpJrnb_X"
      },
      "source": [
        "def android_token_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['ANDROID_TOKEN:' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvwEpdZIjN_9",
        "outputId": "37e9aa03-9ec8-459a-d3e1-13441d3d4ee0"
      },
      "source": [
        "t5.data.TaskRegistry.remove('android_token')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"android_token\",\n",
        "    dataset_fn=nq_android_token,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[android_token_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_android_token\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f15ff6c9160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6z53ZuUpT3f",
        "outputId": "8f41a8db-59c9-419d-9056-1692b143ca0d"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"android_token\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 256, \"targets\": 256})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'ANDROID_TOKEN:protected Fragment getCurrentFrag() { List<Fragment> fragments = getListFrag(); if (fragments != null) { for (Fragment fragment : fragments <extra_id_0> if (fragment != null && fragment.isVisible()) { return fragment; } } } return null; }', 'inputs': array([    3, 16446,    15,  2591,    56, 18728,  7272,  1873, 18843,\n",
            "          16,     7,    85,    25,   619,    29, 14332,    11,  7240,\n",
            "       18843,    18,    21,    17,  2604,    22,    49,    30,     8,\n",
            "           7,    50,    17,   619,  1691,    58, 14332, 32099,    21,\n",
            "          17,  2604,    49,    30,    91,  1691,     4,  6000,    60,\n",
            "           7,    14,  1691,    13,     6,     6,     6,    14,    30,\n",
            "          13,     6,     1], dtype=int32), 'targets_pretokenized': b') {', 'targets': array([3, 8, 7, 1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_TOKEN:public View findViewById(int id) { if (mCachedViews.containsKey(id)) { return mCachedViews.get(id); } else { View view = mRootView.findViewById(id); if <extra_id_0> mCachedViews.put(id, view); } return view; } }', 'inputs': array([    3, 16446,    15,  2591,    56,  4569,   886,  3510,     5,\n",
            "          53,   176,     8,     7,    21,    17, 19807,  4197,     4,\n",
            "         833,     5,   111,     8,     8,     7,    14,     3, 19807,\n",
            "        4197,     4,    33,     5,   111,    10,     6,    77,     7,\n",
            "         886,   403,    11, 23258,     4,  1514,     5,   111,    10,\n",
            "          21, 32099,     3, 19807,  4197,     4,   120,     5,   111,\n",
            "           9,   403,    10,     6,    14,   403,    13,     6,     6,\n",
            "           1], dtype=int32), 'targets_pretokenized': b'(view != null) {', 'targets': array([ 17, 712,  49,  30,   8,   7,   1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_TOKEN:static String getCreateTableQuery() { return \"CREATE TABLE \" <extra_id_0> Columns._ID + TYPE_INTEGER + TYPE_KEY + COMMA + Columns.LATITUDE + TYPE_DOUBLE + COMMA + Columns.LONGITUDE + TYPE_DOUBLE + COMMA + Columns.PROVIDER_CODE + TYPE_TEXT + COMMA + Columns.CODE + TYPE_TEXT + \")\"; }', 'inputs': array([    3, 16446,    15,  2591,    56,  3992,    26,    41, 22983,\n",
            "           2,   179,    16,     7,    14,    32,  3298,  5339,    32,\n",
            "       32099,     3,  1049,     4,    15,   142,    34,   299,     2,\n",
            "         361,    15,  9291,    34,   299,     2,   361,    15,   370,\n",
            "           2,    34,     3, 11768,    34,     3,  1049,     4, 29990,\n",
            "          34,   299,     2,   361,    15,  5980,    34,     3, 11768,\n",
            "          34,     3,  1049,     4, 30371,    34,   299,     2,   361,\n",
            "          15,  5980,    34,     3, 11768,    34,     3,  1049,     4,\n",
            "        6477,    15,  1556,    34,   299,     2,   361,    15,   989,\n",
            "           2,    70,    34,     3, 11768,    34,     3,  1049,     4,\n",
            "        1556,    34,   299,     2,   361,    15,   989,     2,    70,\n",
            "          34,  4422,     6,     1], dtype=int32), 'targets_pretokenized': b'+ TABLE + \" (\" +', 'targets': array([  34, 5339,   34,   32,    3,   28,   34,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_TOKEN:public void resetGame() { for( <extra_id_0> makeSpaceOpen(b); } findViewById(R.id.button_ticTacToeReset).setVisibility(View.INVISIBLE); PLAYING = PLAYER_X; }', 'inputs': array([    3, 16446,    15,  2591,    56,  4569,    20,  1044,  2040,\n",
            "          16,     7,    50,     5, 32099,   900,  1156,  1158,     5,\n",
            "         214,    10,     6,  3510,     5,   144,     4,   111,     4,\n",
            "        1929,    15,  8279,    70,  1810,   129,   110,  3395,     8,\n",
            "           4,  1549,     5,   143,     4,  8864,    10,     3,  3882,\n",
            "           2,  1254,    11,     3,  3882,     2,  1387,    15,     2,\n",
            "          13,     6,     1], dtype=int32), 'targets_pretokenized': b'Button b : availableMoves){', 'targets': array([   3,  448,  238,   58, 1817, 2401,   22,  212,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_TOKEN:public synchronized Map<String, Bitmap> getEmotionsPics() { if (emotionsPic != null && emotionsPic.size() > 0) { return emotionsPic <extra_id_0> } else { getEmotionsTask(); return emotionsPic.get(SmileyMap.GENERAL_EMOTION_POSITION); } }', 'inputs': array([    3, 16446,    15,  2591,    56,  4569,   310,   188,    25,\n",
            "          31,     9,  2857,    29,  8356,  6814,    22, 23951,    22,\n",
            "          16,     7,    21,    17,   110,  6814,    22, 23951,    49,\n",
            "          30,    91,    57,  6814,    22, 23951,     4,   134,    16,\n",
            "           3,    29,   178,     7,    14,    57,  6814,    22, 23951,\n",
            "       32099,     6,    77,     7,  8356,  6814,    22,   389,    18,\n",
            "          14,    57,  6814,    22, 23951,     4,    33,     5, 15657,\n",
            "         264,   100,     4, 16095,    15, 25289, 11740,    15,  6519,\n",
            "          10,     6,     6,     1], dtype=int32), 'targets_pretokenized': b'.get(SmileyMap.GENERAL_EMOTION_POSITION);', 'targets': array([    3,     4,    33,     5, 15657,   264,   100,     4, 16095,\n",
            "          15, 25289, 11740,    15,  6519,    10,     1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q3xYhUwoBC6"
      },
      "source": [
        "ANDROID BLOCK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqvJtXAKjOFn",
        "outputId": "bea53df5-6fbb-4ce2-d564-665ea0b7460e"
      },
      "source": [
        "def nq_android_block(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_android_block[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw valid examples...\")\n",
        "for ex in tfds.as_numpy(nq_android_block(\"validation\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw valid examples...\n",
            "{'input': b'public void update() { if(Gdx.input.isKeyPressed(Keys.LEFT))<extra_id_0> if(Gdx.input.isKeyPressed(Keys.RIGHT)){ bucket.x += 200 * Gdx.graphics.getDeltaTime(); } if (bucket.x < 0) bucket.x = 0; if (bucket.x > 320 - 64) bucket.x = 320 - 64; }', 'output': b'{ bucket.x -= 200 * Gdx.graphics.getDeltaTime(); }'}\n",
            "{'input': b'public void update() { if(Gdx.input.isKeyPressed(Keys.LEFT)){ bucket.x -= 200 * Gdx.graphics.getDeltaTime(); } if(Gdx.input.isKeyPressed(Keys.RIGHT))<extra_id_0> if (bucket.x < 0) bucket.x = 0; if (bucket.x > 320 - 64) bucket.x = 320 - 64; }', 'output': b'{ bucket.x += 200 * Gdx.graphics.getDeltaTime(); }'}\n",
            "{'input': b'public void update() { if(Gdx.input.isKeyPressed(Keys.LEFT)){ bucket.x -= 200 * Gdx.graphics.getDeltaTime(); } if(Gdx.input.isKeyPressed(Keys.RIGHT)){ bucket.x += 200 * Gdx.graphics.getDeltaTime(); } if (bucket.x < 0) <extra_id_0> if (bucket.x > 320 - 64) bucket.x = 320 - 64; }', 'output': b'bucket.x = 0;'}\n",
            "{'input': b'public void update() { if(Gdx.input.isKeyPressed(Keys.LEFT)){ bucket.x -= 200 * Gdx.graphics.getDeltaTime(); } if(Gdx.input.isKeyPressed(Keys.RIGHT)){ bucket.x += 200 * Gdx.graphics.getDeltaTime(); } if (bucket.x < 0) bucket.x = 0; if (bucket.x > 320 - 64) <extra_id_0> }', 'output': b'bucket.x = 320 - 64;'}\n",
            "{'input': b'public String getTitle() throws IOException, StringIndexOutOfBoundsException { Map<String, String> data = getMetadata(); if (data == null || !data.containsKey(\"StreamTitle\")) <extra_id_0> String streamTitle = data.get(\"StreamTitle\"); String artist = streamTitle.substring(streamTitle.indexOf(\"-\") + 1); return artist.trim(); }', 'output': b'{ return \"\"; }'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvADtjcHoGCM"
      },
      "source": [
        "def android_block_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['ANDROID_BLOCK:' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY6Cr6OyoGLR",
        "outputId": "efb68bea-7ef7-4db1-b0b9-294ed64c97d2"
      },
      "source": [
        "t5.data.TaskRegistry.remove('android_block')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"android_block\",\n",
        "    dataset_fn=nq_android_block,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[android_block_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_android_block\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f15ff4a8710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIpCwr6FjOMd",
        "outputId": "aef5e071-aa21-4faa-9fad-0ac53ef19ce6"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"android_block\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 256, \"targets\": 256})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'ANDROID_BLOCK:private void cancelNotification(final BluetoothDevice device) { final NotificationManager nm = (NotificationManager) getSystemService(NOTIFICATION_SERVICE); if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) <extra_id_0> else { nm.cancel(device.getAddress(), NOTIFICATION_ID); } }', 'inputs': array([    3, 16446,    15,  3517,    56,  8797,    20,  2058,   836,\n",
            "           5,    64, 14114,   979,     8,     7,    44,  1895,   121,\n",
            "       11464,    11,    17,   836,   121,     8,     3,  2685,     5,\n",
            "        4684,    15,  1455,    10,    21,    17,  1042,     4,  1235,\n",
            "           4,  4090,    15,  2037,   453,  3080,     4,  1235,    15,\n",
            "        4858,     4,   935,     8, 32099,    77,     7, 11464,     4,\n",
            "        1753,     5,  1529,     4,  3569,    72,     3,  4684,    15,\n",
            "         142,    10,     6,     6,     1], dtype=int32), 'targets_pretokenized': b'{ stopForeground(true); }', 'targets': array([   7,  951, 4349,    5,  225,   10,    6,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_BLOCK:void selectionChanged() { if (mOnItemSelectedListener != null) { if (mInLayout || mBlockLayoutRequests) { if (mSelectionNotifier == null) <extra_id_0> post(mSelectionNotifier); } else { fireOnSelected(); } } if (mSelectedPosition != ListView.INVALID_POSITION && isShown() && !isInTouchMode()) { sendAccessibilityEvent(AccessibilityEvent.TYPE_VIEW_SELECTED); } }', 'inputs': array([    3, 16446,    15,  3517,    56,  9795,     3, 20078,    16,\n",
            "           7,    21,    17, 14873,  3966,   222,    49,    30,     8,\n",
            "           7,    21,    17,    87,   213,   673,     3,     2,    54,\n",
            "         326,   673,  3246,     8,     7,    21,    17,    87,   793,\n",
            "        3532,    40,    30,     8, 32099,  1335,     5,    87,   793,\n",
            "        3532,    10,     6,    77,     7,  2113,   355,  1390,    18,\n",
            "           6,     6,    21,    17, 16677,   392,    49,     3,  3217,\n",
            "           4,  3638,    15,  6519,    91,     3, 26983,    16,    91,\n",
            "         232,  5798,  3447,   270,    60,     7,   797,  4731,   135,\n",
            "           5,  4731,   135,     4,    70,     2,   361,    15,  2846,\n",
            "          15,  9738,    10,     6,     6,     1], dtype=int32), 'targets_pretokenized': b'{ mSelectionNotifier = new SelectionNotifier(); }', 'targets': array([   7,   54,  793, 3532,   11,   24,    3,  793, 3532,   18,    6,\n",
            "          1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_BLOCK:public void run() { if (longInc) { setValueImpl(currValue + 1); } else if (longDec) <extra_id_0> else { return; } long longSpeed = 300; longHandler.postDelayed(this, longSpeed); }', 'inputs': array([    3, 16446,    15,  3517,    56,  4569,    20,   333,    16,\n",
            "           7,    21,    17,   288, 19191,     8,     7,  2996,   262,\n",
            "           5,  6159,   106,    34,   581,     6,    77,    21,    17,\n",
            "         288,  9937,     8, 32099,    77,     7,    14,    13,     6,\n",
            "         126,   126,  1946,    11,     3,     2, 10130,   126,   192,\n",
            "           4, 13592,     5,    75,     9,   126,  1946,    10,     6,\n",
            "           1], dtype=int32), 'targets_pretokenized': b'{ setValueImpl(currValue - 1); }', 'targets': array([   7, 2996,  262,    5, 6159,  106,  139,  581,    6,    1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_BLOCK:public boolean importPrivateKey(String privateKey, String importedKeyPassword, String walletPassword) { String decryptedKey = importedKeyPassword == null || importedKeyPassword == \"\" ? privateKey : decryptPrivateKey(privateKey, importedKeyPassword); if (passwordProtectedProfile) { if (checkPassword(walletPassword)) { addPrivateKey(decryptedKey, walletPassword); } else <extra_id_0> } else { addPrivateKey(decryptedKey, null); } return true; }', 'inputs': array([    3, 16446,    15,  3517,    56,  4569,    45,  2701,  3800,\n",
            "           5,    31, 10956,     9,    26, 13750,   133,   962,     9,\n",
            "          26, 10975,   962,     8,     7,    26,  9785,   159,   133,\n",
            "          11, 13750,   133,   962,    40,    30,     3,     2, 13750,\n",
            "         133,   962,    40,  2252,     3,     2, 10956,    58,  9785,\n",
            "        3800,     5, 14835,     9, 13750,   133,   962,    10,    21,\n",
            "          17,  1696,  7839,   853,     8,     7,    21,    17,   847,\n",
            "         962,     5,  4337,   962,     8,     8,     7,   162,  3800,\n",
            "           5, 15706,   159,   133,     9, 10975,   962,    10,     6,\n",
            "          77, 32099,     6,    77,     7,   162,  3800,     5, 15706,\n",
            "         159,   133,     9,    30,    10,     6,    14,    89,    13,\n",
            "           6,     1], dtype=int32), 'targets_pretokenized': b'{ return false; }', 'targets': array([ 7, 14, 76, 13,  6,  1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'ANDROID_BLOCK:public boolean onOptionsItemSelected(MenuItem item) { switch (item.getItemId()) { case R.id.search_menu_random_search: try <extra_id_0> catch (FamiliarDbException e) { handleFamiliarDbException(true); } return true; default: return super.onOptionsItemSelected(item); } }', 'inputs': array([    3, 16446,    15,  3517,    56,  4569,    45,  9285,  3966,\n",
            "           5,  1938,   323,     8,     7,   695,    17,   440,     4,\n",
            "        5382,    60,     7,   234,   544,     4,   111,     4,  1508,\n",
            "          15,  1601,    15,  2215,    15,  1508,    56,    93, 32099,\n",
            "          97,    17, 21725,  1614,    38,    57,     8,     7,   508,\n",
            "       21725,  1614,    38,     5,   225,    10,     6,    14,    89,\n",
            "          13,   289,    56,    14,    52,     4, 10054,  3966,     5,\n",
            "         440,    10,     6,     6,     1], dtype=int32), 'targets_pretokenized': b'{ startCardViewFrag(-1); }', 'targets': array([    7,   241, 19114, 18843,  6953,     6,     1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0chadICjOT_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT7xGY78HDbh"
      },
      "source": [
        "### Hyper Parameter tuning\n",
        "You can run the HP tuning using the following cells.  \n",
        "Please set the correct path of the variable *MODEL_DIR* (the path to save the pretrained model in), *PATH_GIN_FILE* (the gin file configuration for this HP tuning) and *PRETRAINED_DIR* (the folder that contains the pretrained model).  \n",
        "**Keep attention** to change the *pretrained_model_dir* in finetune step (if you are starting the HP tuning from scratch you have to set the value *PRETRAINED_DIR*, if you are restarting the HP tuning from a previous saved checkpoint you have to set the value *MODEL_DIR*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz1a1TxFNKmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a72c24-31b4-4c01-a9ec-c4ba3e5a7b6e"
      },
      "source": [
        "def _rate_num_input_examples(task):\n",
        "  if \"train\" in task.splits:\n",
        "    return float(task.num_input_examples(\"train\"))\n",
        "  elif \"validation\" in task.splits:\n",
        "    return float(task.num_input_examples(\"validation\"))\n",
        "  else:\n",
        "    raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))\n",
        "\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"all_tasks\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"all_tasks\",\n",
        "    [\"java_construct\", \"java_token\", \"java_block\", \"android_construct\", \"android_token\", \"android_block\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        "     #default_rate=1.0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.seqio.dataset_providers.Mixture at 0x7f15ff64e5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSh7F89Zqb6"
      },
      "source": [
        "from mesh_tensorflow.transformer.learning_rate_schedules import slanted_triangular\n",
        "\n",
        "MODEL_SIZE = \"small\" \n",
        "\n",
        "# Set the folder where the checkpoints and all the others information will be writed\n",
        "MODEL_DIR = 'gs://bucket_code_completion/T5_extension/HP_TUNING/constant/model'\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://bucket_code_completion/T5_extension/pretrained_with_masking'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 16),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = t5.models.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    learning_rate_schedule = 0.001,\n",
        "    sequence_length={\"inputs\": 256, \"targets\": 256},\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oHp5ScE7nf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842186b4-d464-4512-c4cc-c314e8c81d7c"
      },
      "source": [
        "PATH_GIN_FILE = 'gs://bucket_code_completion/T5_extension/HP_TUNING/constant/operative_config.gin'\n",
        "import gin\n",
        "\n",
        "with gin.unlock_config():\n",
        "    gin.parse_config_file(PATH_GIN_FILE)\n",
        "    #RUN FINE-TUNING\n",
        "    FINETUNE_STEPS = 100000\n",
        "    model.finetune(\n",
        "        mixture_or_task_name=\"all_tasks\",\n",
        "        pretrained_model_dir=PRETRAINED_DIR,\n",
        "        finetune_steps=FINETUNE_STEPS\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_comment_completion/Matteo/HP_TUNING/constant/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_comment_completion/Matteo/HP_TUNING/constant/operative_config.gin\n",
            "INFO:root:system_path_file_exists:gs://bucket_comment_completion/Matteo/pretrained_with_masking/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_comment_completion/Matteo/pretrained_with_masking/operative_config.gin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_comment_completion/Matteo/HP_TUNING/constant/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.84.84.90:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.84.84.90:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.84.84.90:8470', '_evaluation_master': 'grpc://10.84.84.90:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f15ff5c22e8>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.84.84.90:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.84.84.90:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, -4527351499860435327)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1283413015379929484)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -5436394702708636675)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1217860787191530939)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 4640495784310756575)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -5200699589764100810)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3113537031664170524)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -3884714794965643480)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -2366246491010807377)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 8317204096308258173)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -5181513522210008943)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('ensemble', 'ensemble'), ('vocab', 'model'), ('batch', 'batch'), ('heads', 'model'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1601563550>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 105     Total size: 60691328         Total slice_size: 60691328       \n",
            "INFO:tensorflow:Counters:\n",
            "allreduce: 5.34e+08\n",
            " allreduce/[0]: 5.34e+08\n",
            "  allreduce/[0]/einsum_op: 4.84e+08\n",
            "  allreduce/[0]/reduce_op: 5.03e+07\n",
            "einsum: 1.93e+13\n",
            "einsum_unique: 1.93e+13\n",
            "output: 1.39e+11\n",
            " output/AddOperation: 2.22e+10\n",
            " output/BinaryOpWithBroadcasting: 1.95e+09\n",
            " output/BroadcastOperation: 7.7e+09\n",
            " output/Constant: 8\n",
            " output/EinsumOperation: 5.94e+10\n",
            " output/ImportOperation: 3.15e+06\n",
            " output/MinMaxOperation: 9.5e+06\n",
            " output/OneHotOperation: 6.52e+09\n",
            " output/RandomOperation: 2.02e+07\n",
            " output/RangeOperation: 4.1e+03\n",
            " output/ReduceOperation: 2e+09\n",
            " output/ReshapeOperation: 6.91e+09\n",
            " output/ScalarAddOperation: 4.99e+08\n",
            " output/ScalarMultiplyOperation: 1.5e+09\n",
            " output/ShiftOperation: 1.31e+05\n",
            " output/SlicewiseOperation: 2.5e+10\n",
            " output/StackOperation: 1.35e+06\n",
            " output/StackedVariable: 1.35e+06\n",
            " output/StopGradient: 4.52e+09\n",
            " output/UnstackOperation: 1.35e+06\n",
            " output/Variable: 4.84e+08\n",
            "output_unique: 1.33e+11\n",
            " output_unique/AddOperation: 2.2e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 1.94e+09\n",
            " output_unique/BroadcastOperation: 7.7e+09\n",
            " output_unique/Constant: 1\n",
            " output_unique/EinsumOperation: 5.69e+10\n",
            " output_unique/ImportOperation: 3.94e+05\n",
            " output_unique/MinMaxOperation: 1.25e+06\n",
            " output_unique/OneHotOperation: 6.34e+09\n",
            " output_unique/RandomOperation: 2.02e+07\n",
            " output_unique/RangeOperation: 512\n",
            " output_unique/ReduceOperation: 1.96e+09\n",
            " output_unique/ReshapeOperation: 6.91e+09\n",
            " output_unique/ScalarAddOperation: 6.42e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.47e+09\n",
            " output_unique/ShiftOperation: 1.31e+05\n",
            " output_unique/SlicewiseOperation: 2.28e+10\n",
            " output_unique/StackOperation: 1.69e+05\n",
            " output_unique/StackedVariable: 1.69e+05\n",
            " output_unique/StopGradient: 4.52e+09\n",
            " output_unique/UnstackOperation: 1.69e+05\n",
            " output_unique/Variable: 6.05e+07\n",
            "variables: 6.07e+07\n",
            " variables/trainable: 6.05e+07\n",
            " variables/untrainable: 1.85e+05\n",
            "INFO:tensorflow:Initializing variables from gs://bucket_comment_completion/Matteo/pretrained_with_masking/model.ckpt-200000:\n",
            "INFO:tensorflow:Variables in gs://bucket_comment_completion/Matteo/pretrained_with_masking/model.ckpt-200000 but not in graph:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Variables in graph but not in gs://bucket_comment_completion/Matteo/pretrained_with_masking/model.ckpt-200000:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Bypassing TPUEstimator hook\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Starting the session.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_comment_completion/Matteo/HP_TUNING/constant/model/model.ckpt-256100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1076: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:773: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 256100...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 256100 into gs://bucket_comment_completion/Matteo/HP_TUNING/constant/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 256100...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:loss = 0.015014648, step = 256200\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014160156, step = 256300 (27.573 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.62668\n",
            "INFO:tensorflow:examples/sec: 928.431\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (2, 24)\n",
            "INFO:tensorflow:loss = 0.01586914, step = 256400 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80282\n",
            "INFO:tensorflow:examples/sec: 973.521\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014831543, step = 256500 (27.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.64606\n",
            "INFO:tensorflow:examples/sec: 933.392\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 48)\n",
            "INFO:tensorflow:loss = 0.015563965, step = 256600 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80293\n",
            "INFO:tensorflow:examples/sec: 973.55\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018066406, step = 256700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80274\n",
            "INFO:tensorflow:examples/sec: 973.502\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 77)\n",
            "INFO:tensorflow:loss = 0.016967773, step = 256800 (26.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80218\n",
            "INFO:tensorflow:examples/sec: 973.358\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01940918, step = 256900 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80288\n",
            "INFO:tensorflow:examples/sec: 973.537\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 257000 (27.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67468\n",
            "INFO:tensorflow:examples/sec: 940.719\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 2)\n",
            "INFO:tensorflow:loss = 0.018920898, step = 257100 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80268\n",
            "INFO:tensorflow:examples/sec: 973.485\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017333984, step = 257200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80299\n",
            "INFO:tensorflow:examples/sec: 973.565\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (11, 31)\n",
            "INFO:tensorflow:loss = 0.016723633, step = 257300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80285\n",
            "INFO:tensorflow:examples/sec: 973.53\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01586914, step = 257400 (27.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67859\n",
            "INFO:tensorflow:examples/sec: 941.719\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 56)\n",
            "INFO:tensorflow:loss = 0.017333984, step = 257500 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80297\n",
            "INFO:tensorflow:examples/sec: 973.561\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017944336, step = 257600 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80287\n",
            "INFO:tensorflow:examples/sec: 973.534\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (15, 85)\n",
            "INFO:tensorflow:loss = 0.016723633, step = 257700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80283\n",
            "INFO:tensorflow:examples/sec: 973.525\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018310547, step = 257800 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80311\n",
            "INFO:tensorflow:examples/sec: 973.597\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018676758, step = 257900 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80293\n",
            "INFO:tensorflow:examples/sec: 973.55\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (18, 10)\n",
            "INFO:tensorflow:loss = 0.018554688, step = 258000 (27.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66558\n",
            "INFO:tensorflow:examples/sec: 938.389\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017211914, step = 258100 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80304\n",
            "INFO:tensorflow:examples/sec: 973.577\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 39)\n",
            "INFO:tensorflow:loss = 0.018432617, step = 258200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80307\n",
            "INFO:tensorflow:examples/sec: 973.586\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017944336, step = 258300 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80276\n",
            "INFO:tensorflow:examples/sec: 973.506\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (22, 68)\n",
            "INFO:tensorflow:loss = 0.016723633, step = 258400 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80291\n",
            "INFO:tensorflow:examples/sec: 973.545\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016357422, step = 258500 (27.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66282\n",
            "INFO:tensorflow:examples/sec: 937.681\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 93)\n",
            "INFO:tensorflow:loss = 0.017456055, step = 258600 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80262\n",
            "INFO:tensorflow:examples/sec: 973.47\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018066406, step = 258700 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80319\n",
            "INFO:tensorflow:examples/sec: 973.617\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018798828, step = 258800 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80305\n",
            "INFO:tensorflow:examples/sec: 973.582\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (27, 22)\n",
            "INFO:tensorflow:loss = 0.020629883, step = 258900 (27.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66918\n",
            "INFO:tensorflow:examples/sec: 939.31\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016357422, step = 259000 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.569\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 47)\n",
            "INFO:tensorflow:loss = 0.017089844, step = 259100 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80325\n",
            "INFO:tensorflow:examples/sec: 973.631\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017700195, step = 259200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80304\n",
            "INFO:tensorflow:examples/sec: 973.579\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (31, 76)\n",
            "INFO:tensorflow:loss = 0.016845703, step = 259300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80279\n",
            "INFO:tensorflow:examples/sec: 973.515\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01574707, step = 259400 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80286\n",
            "INFO:tensorflow:examples/sec: 973.533\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017578125, step = 259500 (27.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66387\n",
            "INFO:tensorflow:examples/sec: 937.95\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (34, 1)\n",
            "INFO:tensorflow:loss = 0.016723633, step = 259600 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80276\n",
            "INFO:tensorflow:examples/sec: 973.508\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018676758, step = 259700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.54\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (36, 30)\n",
            "INFO:tensorflow:loss = 0.017944336, step = 259800 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80284\n",
            "INFO:tensorflow:examples/sec: 973.528\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014160156, step = 259900 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80288\n",
            "INFO:tensorflow:examples/sec: 973.537\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (38, 55)\n",
            "INFO:tensorflow:loss = 0.016601562, step = 260000 (27.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67024\n",
            "INFO:tensorflow:examples/sec: 939.582\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018066406, step = 260100 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80272\n",
            "INFO:tensorflow:examples/sec: 973.497\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (40, 84)\n",
            "INFO:tensorflow:loss = 0.016723633, step = 260200 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8031\n",
            "INFO:tensorflow:examples/sec: 973.593\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 260300 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80307\n",
            "INFO:tensorflow:examples/sec: 973.586\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017700195, step = 260400 (27.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66796\n",
            "INFO:tensorflow:examples/sec: 938.999\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (43, 9)\n",
            "INFO:tensorflow:loss = 0.01940918, step = 260500 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80318\n",
            "INFO:tensorflow:examples/sec: 973.613\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016845703, step = 260600 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80315\n",
            "INFO:tensorflow:examples/sec: 973.607\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (45, 38)\n",
            "INFO:tensorflow:loss = 0.020141602, step = 260700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80285\n",
            "INFO:tensorflow:examples/sec: 973.529\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016601562, step = 260800 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80303\n",
            "INFO:tensorflow:examples/sec: 973.575\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (47, 67)\n",
            "INFO:tensorflow:loss = 0.01574707, step = 260900 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80297\n",
            "INFO:tensorflow:examples/sec: 973.561\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 261000 (27.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65552\n",
            "INFO:tensorflow:examples/sec: 935.813\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (49, 92)\n",
            "INFO:tensorflow:loss = 0.017089844, step = 261100 (26.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80328\n",
            "INFO:tensorflow:examples/sec: 973.639\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01928711, step = 261200 (26.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80325\n",
            "INFO:tensorflow:examples/sec: 973.632\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 261200...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 261200 into gs://bucket_comment_completion/Matteo/HP_TUNING/constant/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 261200...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (51, 90)\n",
            "INFO:tensorflow:loss = 0.014526367, step = 261300 (34.332 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.91273\n",
            "INFO:tensorflow:examples/sec: 745.659\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017089844, step = 261400 (26.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8033\n",
            "INFO:tensorflow:examples/sec: 973.644\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 261500 (27.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67684\n",
            "INFO:tensorflow:examples/sec: 941.272\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (54, 15)\n",
            "INFO:tensorflow:loss = 0.017089844, step = 261600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80299\n",
            "INFO:tensorflow:examples/sec: 973.567\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018432617, step = 261700 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8032\n",
            "INFO:tensorflow:examples/sec: 973.619\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (56, 44)\n",
            "INFO:tensorflow:loss = 0.016479492, step = 261800 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80297\n",
            "INFO:tensorflow:examples/sec: 973.559\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016601562, step = 261900 (27.787 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.59881\n",
            "INFO:tensorflow:examples/sec: 921.296\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (58, 67)\n",
            "INFO:tensorflow:loss = 0.015625, step = 262000 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80321\n",
            "INFO:tensorflow:examples/sec: 973.621\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015136719, step = 262100 (26.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80327\n",
            "INFO:tensorflow:examples/sec: 973.637\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (60, 96)\n",
            "INFO:tensorflow:loss = 0.01928711, step = 262200 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80281\n",
            "INFO:tensorflow:examples/sec: 973.52\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01574707, step = 262300 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80303\n",
            "INFO:tensorflow:examples/sec: 973.575\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018066406, step = 262400 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80303\n",
            "INFO:tensorflow:examples/sec: 973.576\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (63, 21)\n",
            "INFO:tensorflow:loss = 0.017822266, step = 262500 (27.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65909\n",
            "INFO:tensorflow:examples/sec: 936.727\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 262600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80297\n",
            "INFO:tensorflow:examples/sec: 973.56\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (65, 50)\n",
            "INFO:tensorflow:loss = 0.017822266, step = 262700 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80311\n",
            "INFO:tensorflow:examples/sec: 973.596\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018066406, step = 262800 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80265\n",
            "INFO:tensorflow:examples/sec: 973.479\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (67, 79)\n",
            "INFO:tensorflow:loss = 0.016845703, step = 262900 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8032\n",
            "INFO:tensorflow:examples/sec: 973.619\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.019897461, step = 263000 (27.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65927\n",
            "INFO:tensorflow:examples/sec: 936.773\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018432617, step = 263100 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.571\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (70, 4)\n",
            "INFO:tensorflow:loss = 0.018920898, step = 263200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80298\n",
            "INFO:tensorflow:examples/sec: 973.563\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01574707, step = 263300 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80295\n",
            "INFO:tensorflow:examples/sec: 973.554\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (72, 33)\n",
            "INFO:tensorflow:loss = 0.017456055, step = 263400 (27.335 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65837\n",
            "INFO:tensorflow:examples/sec: 936.542\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016113281, step = 263500 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80309\n",
            "INFO:tensorflow:examples/sec: 973.592\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (74, 58)\n",
            "INFO:tensorflow:loss = 0.017456055, step = 263600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80306\n",
            "INFO:tensorflow:examples/sec: 973.583\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01550293, step = 263700 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8026\n",
            "INFO:tensorflow:examples/sec: 973.467\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (76, 87)\n",
            "INFO:tensorflow:loss = 0.01940918, step = 263800 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80306\n",
            "INFO:tensorflow:examples/sec: 973.582\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017333984, step = 263900 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80283\n",
            "INFO:tensorflow:examples/sec: 973.526\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.024658203, step = 264000 (27.324 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65984\n",
            "INFO:tensorflow:examples/sec: 936.92\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (79, 12)\n",
            "INFO:tensorflow:loss = 0.017456055, step = 264100 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80284\n",
            "INFO:tensorflow:examples/sec: 973.527\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017944336, step = 264200 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8027\n",
            "INFO:tensorflow:examples/sec: 973.492\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (81, 41)\n",
            "INFO:tensorflow:loss = 0.020263672, step = 264300 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80278\n",
            "INFO:tensorflow:examples/sec: 973.51\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018310547, step = 264400 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80279\n",
            "INFO:tensorflow:examples/sec: 973.513\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (83, 66)\n",
            "INFO:tensorflow:loss = 0.015136719, step = 264500 (27.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67416\n",
            "INFO:tensorflow:examples/sec: 940.585\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01586914, step = 264600 (26.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80244\n",
            "INFO:tensorflow:examples/sec: 973.425\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (85, 95)\n",
            "INFO:tensorflow:loss = 0.017456055, step = 264700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80281\n",
            "INFO:tensorflow:examples/sec: 973.518\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015625, step = 264800 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8029\n",
            "INFO:tensorflow:examples/sec: 973.543\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015563965, step = 264900 (27.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67412\n",
            "INFO:tensorflow:examples/sec: 940.574\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (88, 20)\n",
            "INFO:tensorflow:loss = 0.017333984, step = 265000 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80273\n",
            "INFO:tensorflow:examples/sec: 973.498\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016235352, step = 265100 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80276\n",
            "INFO:tensorflow:examples/sec: 973.507\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (90, 49)\n",
            "INFO:tensorflow:loss = 0.014892578, step = 265200 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80267\n",
            "INFO:tensorflow:examples/sec: 973.483\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016723633, step = 265300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80278\n",
            "INFO:tensorflow:examples/sec: 973.512\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (92, 78)\n",
            "INFO:tensorflow:loss = 0.017578125, step = 265400 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80294\n",
            "INFO:tensorflow:examples/sec: 973.554\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018676758, step = 265500 (27.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65121\n",
            "INFO:tensorflow:examples/sec: 934.709\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.020019531, step = 265600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80302\n",
            "INFO:tensorflow:examples/sec: 973.573\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (95, 2)\n",
            "INFO:tensorflow:loss = 0.016723633, step = 265700 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.569\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018798828, step = 265800 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8025\n",
            "INFO:tensorflow:examples/sec: 973.439\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (97, 31)\n",
            "INFO:tensorflow:loss = 0.020629883, step = 265900 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80279\n",
            "INFO:tensorflow:examples/sec: 973.515\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 266000 (27.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67096\n",
            "INFO:tensorflow:examples/sec: 939.766\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (99, 56)\n",
            "INFO:tensorflow:loss = 0.016479492, step = 266100 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80288\n",
            "INFO:tensorflow:examples/sec: 973.538\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015258789, step = 266200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80299\n",
            "INFO:tensorflow:examples/sec: 973.564\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (101, 85)\n",
            "INFO:tensorflow:loss = 0.016723633, step = 266300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80291\n",
            "INFO:tensorflow:examples/sec: 973.546\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 266300...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 266300 into gs://bucket_comment_completion/Matteo/HP_TUNING/constant/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 266300...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01574707, step = 266400 (34.903 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.86508\n",
            "INFO:tensorflow:examples/sec: 733.461\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (103, 81)\n",
            "INFO:tensorflow:loss = 0.016967773, step = 266500 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80299\n",
            "INFO:tensorflow:examples/sec: 973.565\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014709473, step = 266600 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80311\n",
            "INFO:tensorflow:examples/sec: 973.595\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018920898, step = 266700 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80273\n",
            "INFO:tensorflow:examples/sec: 973.5\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (106, 10)\n",
            "INFO:tensorflow:loss = 0.014221191, step = 266800 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80299\n",
            "INFO:tensorflow:examples/sec: 973.565\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018066406, step = 266900 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80302\n",
            "INFO:tensorflow:examples/sec: 973.574\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (108, 35)\n",
            "INFO:tensorflow:loss = 0.017089844, step = 267000 (27.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67681\n",
            "INFO:tensorflow:examples/sec: 941.264\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01574707, step = 267100 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80316\n",
            "INFO:tensorflow:examples/sec: 973.608\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (110, 64)\n",
            "INFO:tensorflow:loss = 0.016357422, step = 267200 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80309\n",
            "INFO:tensorflow:examples/sec: 973.592\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017578125, step = 267300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80277\n",
            "INFO:tensorflow:examples/sec: 973.508\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (112, 93)\n",
            "INFO:tensorflow:loss = 0.014221191, step = 267400 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80311\n",
            "INFO:tensorflow:examples/sec: 973.597\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01586914, step = 267500 (27.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66657\n",
            "INFO:tensorflow:examples/sec: 938.641\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014160156, step = 267600 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80272\n",
            "INFO:tensorflow:examples/sec: 973.497\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (115, 18)\n",
            "INFO:tensorflow:loss = 0.015625, step = 267700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80284\n",
            "INFO:tensorflow:examples/sec: 973.527\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016723633, step = 267800 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80317\n",
            "INFO:tensorflow:examples/sec: 973.61\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (117, 47)\n",
            "INFO:tensorflow:loss = 0.016357422, step = 267900 (27.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66281\n",
            "INFO:tensorflow:examples/sec: 937.679\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016357422, step = 268000 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80314\n",
            "INFO:tensorflow:examples/sec: 973.603\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (119, 72)\n",
            "INFO:tensorflow:loss = 0.01574707, step = 268100 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8029\n",
            "INFO:tensorflow:examples/sec: 973.542\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016723633, step = 268200 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80269\n",
            "INFO:tensorflow:examples/sec: 973.487\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017211914, step = 268300 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80255\n",
            "INFO:tensorflow:examples/sec: 973.452\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (122, 1)\n",
            "INFO:tensorflow:loss = 0.01586914, step = 268400 (26.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80241\n",
            "INFO:tensorflow:examples/sec: 973.417\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017211914, step = 268500 (27.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67677\n",
            "INFO:tensorflow:examples/sec: 941.252\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (124, 26)\n",
            "INFO:tensorflow:loss = 0.016845703, step = 268600 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.539\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017333984, step = 268700 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80315\n",
            "INFO:tensorflow:examples/sec: 973.606\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (126, 55)\n",
            "INFO:tensorflow:loss = 0.017456055, step = 268800 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80262\n",
            "INFO:tensorflow:examples/sec: 973.47\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016845703, step = 268900 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80257\n",
            "INFO:tensorflow:examples/sec: 973.458\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (128, 76)\n",
            "INFO:tensorflow:loss = 0.017944336, step = 269000 (28.319 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.53119\n",
            "INFO:tensorflow:examples/sec: 903.984\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016601562, step = 269100 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80274\n",
            "INFO:tensorflow:examples/sec: 973.5\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016601562, step = 269200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.572\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (131, 5)\n",
            "INFO:tensorflow:loss = 0.018310547, step = 269300 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80313\n",
            "INFO:tensorflow:examples/sec: 973.601\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018920898, step = 269400 (27.484 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.63848\n",
            "INFO:tensorflow:examples/sec: 931.451\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (133, 29)\n",
            "INFO:tensorflow:loss = 0.016845703, step = 269500 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80321\n",
            "INFO:tensorflow:examples/sec: 973.621\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018554688, step = 269600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80291\n",
            "INFO:tensorflow:examples/sec: 973.546\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (135, 58)\n",
            "INFO:tensorflow:loss = 0.017944336, step = 269700 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8027\n",
            "INFO:tensorflow:examples/sec: 973.491\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017578125, step = 269800 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80303\n",
            "INFO:tensorflow:examples/sec: 973.577\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (137, 87)\n",
            "INFO:tensorflow:loss = 0.016357422, step = 269900 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80275\n",
            "INFO:tensorflow:examples/sec: 973.505\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016235352, step = 270000 (27.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65634\n",
            "INFO:tensorflow:examples/sec: 936.023\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018798828, step = 270100 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80299\n",
            "INFO:tensorflow:examples/sec: 973.565\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (140, 12)\n",
            "INFO:tensorflow:loss = 0.016113281, step = 270200 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80273\n",
            "INFO:tensorflow:examples/sec: 973.499\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 270300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80284\n",
            "INFO:tensorflow:examples/sec: 973.527\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (142, 41)\n",
            "INFO:tensorflow:loss = 0.015319824, step = 270400 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80296\n",
            "INFO:tensorflow:examples/sec: 973.558\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 270500 (27.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.64893\n",
            "INFO:tensorflow:examples/sec: 934.126\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (144, 65)\n",
            "INFO:tensorflow:loss = 0.018432617, step = 270600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80302\n",
            "INFO:tensorflow:examples/sec: 973.572\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01940918, step = 270700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8029\n",
            "INFO:tensorflow:examples/sec: 973.541\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (146, 94)\n",
            "INFO:tensorflow:loss = 0.018676758, step = 270800 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8032\n",
            "INFO:tensorflow:examples/sec: 973.619\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01928711, step = 270900 (27.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67379\n",
            "INFO:tensorflow:examples/sec: 940.491\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015258789, step = 271000 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80291\n",
            "INFO:tensorflow:examples/sec: 973.546\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (149, 19)\n",
            "INFO:tensorflow:loss = 0.014953613, step = 271100 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80308\n",
            "INFO:tensorflow:examples/sec: 973.588\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015625, step = 271200 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80285\n",
            "INFO:tensorflow:examples/sec: 973.529\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (151, 48)\n",
            "INFO:tensorflow:loss = 0.017578125, step = 271300 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8031\n",
            "INFO:tensorflow:examples/sec: 973.593\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016601562, step = 271400 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8031\n",
            "INFO:tensorflow:examples/sec: 973.593\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 271400...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 271400 into gs://bucket_comment_completion/Matteo/HP_TUNING/constant/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 271400...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (153, 44)\n",
            "INFO:tensorflow:loss = 0.016235352, step = 271500 (34.758 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.877\n",
            "INFO:tensorflow:examples/sec: 736.512\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01550293, step = 271600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80297\n",
            "INFO:tensorflow:examples/sec: 973.559\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (155, 73)\n",
            "INFO:tensorflow:loss = 0.016601562, step = 271700 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80315\n",
            "INFO:tensorflow:examples/sec: 973.605\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017333984, step = 271800 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80283\n",
            "INFO:tensorflow:examples/sec: 973.525\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016723633, step = 271900 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80309\n",
            "INFO:tensorflow:examples/sec: 973.592\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (158, 0)\n",
            "INFO:tensorflow:loss = 0.01550293, step = 272000 (27.818 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.59484\n",
            "INFO:tensorflow:examples/sec: 920.278\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 272100 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8026\n",
            "INFO:tensorflow:examples/sec: 973.466\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (160, 29)\n",
            "INFO:tensorflow:loss = 0.017333984, step = 272200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80305\n",
            "INFO:tensorflow:examples/sec: 973.582\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014953613, step = 272300 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80299\n",
            "INFO:tensorflow:examples/sec: 973.565\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (162, 58)\n",
            "INFO:tensorflow:loss = 0.017089844, step = 272400 (27.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67509\n",
            "INFO:tensorflow:examples/sec: 940.824\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018554688, step = 272500 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80277\n",
            "INFO:tensorflow:examples/sec: 973.509\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (164, 83)\n",
            "INFO:tensorflow:loss = 0.016235352, step = 272600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80294\n",
            "INFO:tensorflow:examples/sec: 973.553\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018676758, step = 272700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80282\n",
            "INFO:tensorflow:examples/sec: 973.522\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015625, step = 272800 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8029\n",
            "INFO:tensorflow:examples/sec: 973.542\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (167, 12)\n",
            "INFO:tensorflow:loss = 0.018920898, step = 272900 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80282\n",
            "INFO:tensorflow:examples/sec: 973.521\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016235352, step = 273000 (27.240 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67109\n",
            "INFO:tensorflow:examples/sec: 939.799\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (169, 37)\n",
            "INFO:tensorflow:loss = 0.017700195, step = 273100 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.54\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018066406, step = 273200 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8032\n",
            "INFO:tensorflow:examples/sec: 973.619\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (171, 66)\n",
            "INFO:tensorflow:loss = 0.015563965, step = 273300 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8028\n",
            "INFO:tensorflow:examples/sec: 973.516\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01574707, step = 273400 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80278\n",
            "INFO:tensorflow:examples/sec: 973.51\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (173, 91)\n",
            "INFO:tensorflow:loss = 0.020263672, step = 273500 (27.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65915\n",
            "INFO:tensorflow:examples/sec: 936.743\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016967773, step = 273600 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80266\n",
            "INFO:tensorflow:examples/sec: 973.482\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016723633, step = 273700 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80306\n",
            "INFO:tensorflow:examples/sec: 973.583\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (176, 20)\n",
            "INFO:tensorflow:loss = 0.016601562, step = 273800 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80307\n",
            "INFO:tensorflow:examples/sec: 973.586\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018676758, step = 273900 (27.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65758\n",
            "INFO:tensorflow:examples/sec: 936.341\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (178, 45)\n",
            "INFO:tensorflow:loss = 0.017211914, step = 274000 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80304\n",
            "INFO:tensorflow:examples/sec: 973.579\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016723633, step = 274100 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80312\n",
            "INFO:tensorflow:examples/sec: 973.599\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (180, 74)\n",
            "INFO:tensorflow:loss = 0.018920898, step = 274200 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8028\n",
            "INFO:tensorflow:examples/sec: 973.518\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015136719, step = 274300 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80308\n",
            "INFO:tensorflow:examples/sec: 973.589\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018310547, step = 274400 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80298\n",
            "INFO:tensorflow:examples/sec: 973.563\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (183, 0)\n",
            "INFO:tensorflow:loss = 0.017333984, step = 274500 (27.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66965\n",
            "INFO:tensorflow:examples/sec: 939.431\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016601562, step = 274600 (26.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80321\n",
            "INFO:tensorflow:examples/sec: 973.621\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (185, 29)\n",
            "INFO:tensorflow:loss = 0.017578125, step = 274700 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80317\n",
            "INFO:tensorflow:examples/sec: 973.611\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016845703, step = 274800 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80279\n",
            "INFO:tensorflow:examples/sec: 973.515\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (187, 58)\n",
            "INFO:tensorflow:loss = 0.016723633, step = 274900 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.803\n",
            "INFO:tensorflow:examples/sec: 973.567\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 275000 (27.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66647\n",
            "INFO:tensorflow:examples/sec: 938.615\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (189, 83)\n",
            "INFO:tensorflow:loss = 0.017333984, step = 275100 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.54\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017944336, step = 275200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.569\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01953125, step = 275300 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80298\n",
            "INFO:tensorflow:examples/sec: 973.562\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (192, 12)\n",
            "INFO:tensorflow:loss = 0.016113281, step = 275400 (27.519 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.6339\n",
            "INFO:tensorflow:examples/sec: 930.278\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018798828, step = 275500 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80311\n",
            "INFO:tensorflow:examples/sec: 973.596\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (194, 36)\n",
            "INFO:tensorflow:loss = 0.016479492, step = 275600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80298\n",
            "INFO:tensorflow:examples/sec: 973.563\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016601562, step = 275700 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8026\n",
            "INFO:tensorflow:examples/sec: 973.465\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (196, 65)\n",
            "INFO:tensorflow:loss = 0.018798828, step = 275800 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.539\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014831543, step = 275900 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.571\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (198, 90)\n",
            "INFO:tensorflow:loss = 0.0154418945, step = 276000 (27.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.6716\n",
            "INFO:tensorflow:examples/sec: 939.929\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014709473, step = 276100 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80322\n",
            "INFO:tensorflow:examples/sec: 973.624\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015563965, step = 276200 (26.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80327\n",
            "INFO:tensorflow:examples/sec: 973.637\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (201, 19)\n",
            "INFO:tensorflow:loss = 0.01550293, step = 276300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80284\n",
            "INFO:tensorflow:examples/sec: 973.528\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017456055, step = 276400 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80287\n",
            "INFO:tensorflow:examples/sec: 973.535\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (203, 44)\n",
            "INFO:tensorflow:loss = 0.01574707, step = 276500 (27.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65462\n",
            "INFO:tensorflow:examples/sec: 935.582\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 276500...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 276500 into gs://bucket_comment_completion/Matteo/HP_TUNING/constant/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 276500...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.012512207, step = 276600 (34.540 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.8952\n",
            "INFO:tensorflow:examples/sec: 741.172\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (205, 41)\n",
            "INFO:tensorflow:loss = 0.015380859, step = 276700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.54\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016845703, step = 276800 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80315\n",
            "INFO:tensorflow:examples/sec: 973.607\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (207, 70)\n",
            "INFO:tensorflow:loss = 0.017944336, step = 276900 (27.457 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.64212\n",
            "INFO:tensorflow:examples/sec: 932.382\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017211914, step = 277000 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80281\n",
            "INFO:tensorflow:examples/sec: 973.52\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (209, 94)\n",
            "INFO:tensorflow:loss = 0.016601562, step = 277100 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80304\n",
            "INFO:tensorflow:examples/sec: 973.579\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016235352, step = 277200 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8029\n",
            "INFO:tensorflow:examples/sec: 973.541\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016601562, step = 277300 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80304\n",
            "INFO:tensorflow:examples/sec: 973.578\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (212, 23)\n",
            "INFO:tensorflow:loss = 0.01574707, step = 277400 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80304\n",
            "INFO:tensorflow:examples/sec: 973.579\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014404297, step = 277500 (27.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65483\n",
            "INFO:tensorflow:examples/sec: 935.638\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (214, 48)\n",
            "INFO:tensorflow:loss = 0.015136719, step = 277600 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80297\n",
            "INFO:tensorflow:examples/sec: 973.559\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01586914, step = 277700 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80314\n",
            "INFO:tensorflow:examples/sec: 973.603\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (216, 77)\n",
            "INFO:tensorflow:loss = 0.014160156, step = 277800 (26.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8025\n",
            "INFO:tensorflow:examples/sec: 973.441\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016723633, step = 277900 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80295\n",
            "INFO:tensorflow:examples/sec: 973.555\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01574707, step = 278000 (27.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67693\n",
            "INFO:tensorflow:examples/sec: 941.294\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (219, 2)\n",
            "INFO:tensorflow:loss = 0.015563965, step = 278100 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80266\n",
            "INFO:tensorflow:examples/sec: 973.481\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016479492, step = 278200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80303\n",
            "INFO:tensorflow:examples/sec: 973.577\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (221, 31)\n",
            "INFO:tensorflow:loss = 0.016357422, step = 278300 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80308\n",
            "INFO:tensorflow:examples/sec: 973.588\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 278400 (27.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67291\n",
            "INFO:tensorflow:examples/sec: 940.265\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (223, 56)\n",
            "INFO:tensorflow:loss = 0.01586914, step = 278500 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80295\n",
            "INFO:tensorflow:examples/sec: 973.556\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.018432617, step = 278600 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80261\n",
            "INFO:tensorflow:examples/sec: 973.467\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (225, 85)\n",
            "INFO:tensorflow:loss = 0.016235352, step = 278700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80287\n",
            "INFO:tensorflow:examples/sec: 973.534\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017333984, step = 278800 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.571\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014953613, step = 278900 (26.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80333\n",
            "INFO:tensorflow:examples/sec: 973.651\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (228, 10)\n",
            "INFO:tensorflow:loss = 0.014770508, step = 279000 (27.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67514\n",
            "INFO:tensorflow:examples/sec: 940.836\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.020019531, step = 279100 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8028\n",
            "INFO:tensorflow:examples/sec: 973.516\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (230, 39)\n",
            "INFO:tensorflow:loss = 0.017089844, step = 279200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80299\n",
            "INFO:tensorflow:examples/sec: 973.566\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 279300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80299\n",
            "INFO:tensorflow:examples/sec: 973.566\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (232, 68)\n",
            "INFO:tensorflow:loss = 0.015625, step = 279400 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8029\n",
            "INFO:tensorflow:examples/sec: 973.543\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01550293, step = 279500 (27.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67704\n",
            "INFO:tensorflow:examples/sec: 941.323\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (234, 93)\n",
            "INFO:tensorflow:loss = 0.017456055, step = 279600 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80275\n",
            "INFO:tensorflow:examples/sec: 973.505\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017700195, step = 279700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8029\n",
            "INFO:tensorflow:examples/sec: 973.543\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01977539, step = 279800 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8027\n",
            "INFO:tensorflow:examples/sec: 973.492\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (237, 22)\n",
            "INFO:tensorflow:loss = 0.014404297, step = 279900 (27.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67465\n",
            "INFO:tensorflow:examples/sec: 940.71\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016357422, step = 280000 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80272\n",
            "INFO:tensorflow:examples/sec: 973.497\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (239, 47)\n",
            "INFO:tensorflow:loss = 0.017211914, step = 280100 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80294\n",
            "INFO:tensorflow:examples/sec: 973.554\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01953125, step = 280200 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.539\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (241, 76)\n",
            "INFO:tensorflow:loss = 0.021484375, step = 280300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80286\n",
            "INFO:tensorflow:examples/sec: 973.531\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014404297, step = 280400 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80287\n",
            "INFO:tensorflow:examples/sec: 973.534\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016357422, step = 280500 (27.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66759\n",
            "INFO:tensorflow:examples/sec: 938.902\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (244, 1)\n",
            "INFO:tensorflow:loss = 0.017944336, step = 280600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.541\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014892578, step = 280700 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80271\n",
            "INFO:tensorflow:examples/sec: 973.494\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (246, 30)\n",
            "INFO:tensorflow:loss = 0.017944336, step = 280800 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80272\n",
            "INFO:tensorflow:examples/sec: 973.496\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01550293, step = 280900 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8028\n",
            "INFO:tensorflow:examples/sec: 973.517\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (248, 55)\n",
            "INFO:tensorflow:loss = 0.0138549805, step = 281000 (27.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67333\n",
            "INFO:tensorflow:examples/sec: 940.372\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01373291, step = 281100 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80298\n",
            "INFO:tensorflow:examples/sec: 973.562\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (250, 84)\n",
            "INFO:tensorflow:loss = 0.014953613, step = 281200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.803\n",
            "INFO:tensorflow:examples/sec: 973.567\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015563965, step = 281300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.539\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01586914, step = 281400 (27.529 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.63253\n",
            "INFO:tensorflow:examples/sec: 929.929\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (253, 8)\n",
            "INFO:tensorflow:loss = 0.015380859, step = 281500 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80271\n",
            "INFO:tensorflow:examples/sec: 973.493\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016357422, step = 281600 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80285\n",
            "INFO:tensorflow:examples/sec: 973.529\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 281600...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 281600 into gs://bucket_comment_completion/Matteo/HP_TUNING/constant/model/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:970: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 281600...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (255, 0)\n",
            "INFO:tensorflow:loss = 0.016479492, step = 281700 (47.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.11099\n",
            "INFO:tensorflow:examples/sec: 540.413\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016479492, step = 281800 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80278\n",
            "INFO:tensorflow:examples/sec: 973.511\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (257, 25)\n",
            "INFO:tensorflow:loss = 0.016723633, step = 281900 (27.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.6703\n",
            "INFO:tensorflow:examples/sec: 939.598\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015136719, step = 282000 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80293\n",
            "INFO:tensorflow:examples/sec: 973.55\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (259, 54)\n",
            "INFO:tensorflow:loss = 0.017944336, step = 282100 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80293\n",
            "INFO:tensorflow:examples/sec: 973.55\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01361084, step = 282200 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80313\n",
            "INFO:tensorflow:examples/sec: 973.602\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (261, 83)\n",
            "INFO:tensorflow:loss = 0.015136719, step = 282300 (28.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.52026\n",
            "INFO:tensorflow:examples/sec: 901.187\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016845703, step = 282400 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8031\n",
            "INFO:tensorflow:examples/sec: 973.592\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016479492, step = 282500 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80308\n",
            "INFO:tensorflow:examples/sec: 973.589\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (264, 4)\n",
            "INFO:tensorflow:loss = 0.015136719, step = 282600 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8026\n",
            "INFO:tensorflow:examples/sec: 973.466\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015197754, step = 282700 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80276\n",
            "INFO:tensorflow:examples/sec: 973.507\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (266, 33)\n",
            "INFO:tensorflow:loss = 0.014709473, step = 282800 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80267\n",
            "INFO:tensorflow:examples/sec: 973.485\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016479492, step = 282900 (27.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67626\n",
            "INFO:tensorflow:examples/sec: 941.124\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (268, 58)\n",
            "INFO:tensorflow:loss = 0.018554688, step = 283000 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80298\n",
            "INFO:tensorflow:examples/sec: 973.564\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016845703, step = 283100 (26.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80324\n",
            "INFO:tensorflow:examples/sec: 973.63\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (270, 87)\n",
            "INFO:tensorflow:loss = 0.016235352, step = 283200 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8029\n",
            "INFO:tensorflow:examples/sec: 973.542\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014404297, step = 283300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80288\n",
            "INFO:tensorflow:examples/sec: 973.536\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016601562, step = 283400 (27.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67605\n",
            "INFO:tensorflow:examples/sec: 941.07\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (273, 12)\n",
            "INFO:tensorflow:loss = 0.016967773, step = 283500 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80281\n",
            "INFO:tensorflow:examples/sec: 973.518\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016113281, step = 283600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80304\n",
            "INFO:tensorflow:examples/sec: 973.577\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (275, 41)\n",
            "INFO:tensorflow:loss = 0.016601562, step = 283700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80292\n",
            "INFO:tensorflow:examples/sec: 973.548\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016845703, step = 283800 (27.349 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65641\n",
            "INFO:tensorflow:examples/sec: 936.04\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (277, 66)\n",
            "INFO:tensorflow:loss = 0.016235352, step = 283900 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80298\n",
            "INFO:tensorflow:examples/sec: 973.562\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017578125, step = 284000 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80294\n",
            "INFO:tensorflow:examples/sec: 973.553\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (279, 95)\n",
            "INFO:tensorflow:loss = 0.014953613, step = 284100 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80288\n",
            "INFO:tensorflow:examples/sec: 973.538\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01550293, step = 284200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80296\n",
            "INFO:tensorflow:examples/sec: 973.557\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015563965, step = 284300 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8031\n",
            "INFO:tensorflow:examples/sec: 973.593\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (282, 18)\n",
            "INFO:tensorflow:loss = 0.016235352, step = 284400 (27.727 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.60661\n",
            "INFO:tensorflow:examples/sec: 923.292\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01574707, step = 284500 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80316\n",
            "INFO:tensorflow:examples/sec: 973.609\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (284, 47)\n",
            "INFO:tensorflow:loss = 0.015625, step = 284600 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80261\n",
            "INFO:tensorflow:examples/sec: 973.469\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016235352, step = 284700 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.571\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (286, 76)\n",
            "INFO:tensorflow:loss = 0.016723633, step = 284800 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80318\n",
            "INFO:tensorflow:examples/sec: 973.613\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017333984, step = 284900 (27.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67925\n",
            "INFO:tensorflow:examples/sec: 941.887\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014709473, step = 285000 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80279\n",
            "INFO:tensorflow:examples/sec: 973.513\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (289, 1)\n",
            "INFO:tensorflow:loss = 0.018554688, step = 285100 (26.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80318\n",
            "INFO:tensorflow:examples/sec: 973.614\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014831543, step = 285200 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8031\n",
            "INFO:tensorflow:examples/sec: 973.595\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (291, 30)\n",
            "INFO:tensorflow:loss = 0.016235352, step = 285300 (27.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67183\n",
            "INFO:tensorflow:examples/sec: 939.989\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.019042969, step = 285400 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.571\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (293, 55)\n",
            "INFO:tensorflow:loss = 0.016235352, step = 285500 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80305\n",
            "INFO:tensorflow:examples/sec: 973.581\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016113281, step = 285600 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80277\n",
            "INFO:tensorflow:examples/sec: 973.509\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (295, 84)\n",
            "INFO:tensorflow:loss = 0.017456055, step = 285700 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80314\n",
            "INFO:tensorflow:examples/sec: 973.604\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016235352, step = 285800 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80298\n",
            "INFO:tensorflow:examples/sec: 973.562\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014831543, step = 285900 (27.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67163\n",
            "INFO:tensorflow:examples/sec: 939.937\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (298, 9)\n",
            "INFO:tensorflow:loss = 0.014831543, step = 286000 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80306\n",
            "INFO:tensorflow:examples/sec: 973.583\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015625, step = 286100 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80308\n",
            "INFO:tensorflow:examples/sec: 973.59\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (300, 38)\n",
            "INFO:tensorflow:loss = 0.014526367, step = 286200 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80258\n",
            "INFO:tensorflow:examples/sec: 973.46\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01574707, step = 286300 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80307\n",
            "INFO:tensorflow:examples/sec: 973.587\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (302, 63)\n",
            "INFO:tensorflow:loss = 0.014343262, step = 286400 (27.349 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65651\n",
            "INFO:tensorflow:examples/sec: 936.067\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015319824, step = 286500 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.803\n",
            "INFO:tensorflow:examples/sec: 973.568\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (304, 92)\n",
            "INFO:tensorflow:loss = 0.014038086, step = 286600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80288\n",
            "INFO:tensorflow:examples/sec: 973.537\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0146484375, step = 286700 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80298\n",
            "INFO:tensorflow:examples/sec: 973.563\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 286700...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 286700 into gs://bucket_comment_completion/Matteo/HP_TUNING/constant/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 286700...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (306, 91)\n",
            "INFO:tensorflow:loss = 0.018798828, step = 286800 (35.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.84807\n",
            "INFO:tensorflow:examples/sec: 729.107\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016723633, step = 286900 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80275\n",
            "INFO:tensorflow:examples/sec: 973.504\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017700195, step = 287000 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.57\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (309, 16)\n",
            "INFO:tensorflow:loss = 0.014770508, step = 287100 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80277\n",
            "INFO:tensorflow:examples/sec: 973.509\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015625, step = 287200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80298\n",
            "INFO:tensorflow:examples/sec: 973.564\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (311, 45)\n",
            "INFO:tensorflow:loss = 0.014282227, step = 287300 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80274\n",
            "INFO:tensorflow:examples/sec: 973.501\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016601562, step = 287400 (27.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67614\n",
            "INFO:tensorflow:examples/sec: 941.091\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (313, 70)\n",
            "INFO:tensorflow:loss = 0.015197754, step = 287500 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80263\n",
            "INFO:tensorflow:examples/sec: 973.473\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014526367, step = 287600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80294\n",
            "INFO:tensorflow:examples/sec: 973.551\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (315, 99)\n",
            "INFO:tensorflow:loss = 0.013793945, step = 287700 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80261\n",
            "INFO:tensorflow:examples/sec: 973.468\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01550293, step = 287800 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80287\n",
            "INFO:tensorflow:examples/sec: 973.534\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017211914, step = 287900 (27.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67406\n",
            "INFO:tensorflow:examples/sec: 940.56\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (318, 24)\n",
            "INFO:tensorflow:loss = 0.014953613, step = 288000 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80272\n",
            "INFO:tensorflow:examples/sec: 973.496\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017089844, step = 288100 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80297\n",
            "INFO:tensorflow:examples/sec: 973.561\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (320, 53)\n",
            "INFO:tensorflow:loss = 0.016845703, step = 288200 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80314\n",
            "INFO:tensorflow:examples/sec: 973.603\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014892578, step = 288300 (27.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67888\n",
            "INFO:tensorflow:examples/sec: 941.794\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (322, 78)\n",
            "INFO:tensorflow:loss = 0.017089844, step = 288400 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80313\n",
            "INFO:tensorflow:examples/sec: 973.603\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017211914, step = 288500 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80304\n",
            "INFO:tensorflow:examples/sec: 973.579\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015136719, step = 288600 (26.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80253\n",
            "INFO:tensorflow:examples/sec: 973.447\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (325, 7)\n",
            "INFO:tensorflow:loss = 0.014709473, step = 288700 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80303\n",
            "INFO:tensorflow:examples/sec: 973.576\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017089844, step = 288800 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80278\n",
            "INFO:tensorflow:examples/sec: 973.512\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (327, 32)\n",
            "INFO:tensorflow:loss = 0.015625, step = 288900 (27.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.6721\n",
            "INFO:tensorflow:examples/sec: 940.057\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014953613, step = 289000 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80312\n",
            "INFO:tensorflow:examples/sec: 973.599\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (329, 61)\n",
            "INFO:tensorflow:loss = 0.016845703, step = 289100 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80306\n",
            "INFO:tensorflow:examples/sec: 973.584\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014953613, step = 289200 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80284\n",
            "INFO:tensorflow:examples/sec: 973.527\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (331, 90)\n",
            "INFO:tensorflow:loss = 0.016357422, step = 289300 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8031\n",
            "INFO:tensorflow:examples/sec: 973.594\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01586914, step = 289400 (27.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66012\n",
            "INFO:tensorflow:examples/sec: 936.991\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017089844, step = 289500 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80266\n",
            "INFO:tensorflow:examples/sec: 973.48\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (334, 15)\n",
            "INFO:tensorflow:loss = 0.016113281, step = 289600 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80294\n",
            "INFO:tensorflow:examples/sec: 973.553\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016235352, step = 289700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80284\n",
            "INFO:tensorflow:examples/sec: 973.526\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (336, 44)\n",
            "INFO:tensorflow:loss = 0.015991211, step = 289800 (27.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66193\n",
            "INFO:tensorflow:examples/sec: 937.455\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0146484375, step = 289900 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80272\n",
            "INFO:tensorflow:examples/sec: 973.495\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (338, 69)\n",
            "INFO:tensorflow:loss = 0.016235352, step = 290000 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80297\n",
            "INFO:tensorflow:examples/sec: 973.559\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014709473, step = 290100 (26.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80223\n",
            "INFO:tensorflow:examples/sec: 973.371\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (340, 98)\n",
            "INFO:tensorflow:loss = 0.016601562, step = 290200 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80283\n",
            "INFO:tensorflow:examples/sec: 973.525\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.013061523, step = 290300 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80296\n",
            "INFO:tensorflow:examples/sec: 973.559\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016357422, step = 290400 (27.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65026\n",
            "INFO:tensorflow:examples/sec: 934.467\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (343, 22)\n",
            "INFO:tensorflow:loss = 0.015625, step = 290500 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80277\n",
            "INFO:tensorflow:examples/sec: 973.508\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016601562, step = 290600 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80306\n",
            "INFO:tensorflow:examples/sec: 973.583\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (345, 51)\n",
            "INFO:tensorflow:loss = 0.015380859, step = 290700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80295\n",
            "INFO:tensorflow:examples/sec: 973.555\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015258789, step = 290800 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80276\n",
            "INFO:tensorflow:examples/sec: 973.505\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (347, 76)\n",
            "INFO:tensorflow:loss = 0.01574707, step = 290900 (27.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67714\n",
            "INFO:tensorflow:examples/sec: 941.347\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015014648, step = 291000 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8026\n",
            "INFO:tensorflow:examples/sec: 973.466\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.012512207, step = 291100 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.541\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (350, 5)\n",
            "INFO:tensorflow:loss = 0.016113281, step = 291200 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8031\n",
            "INFO:tensorflow:examples/sec: 973.593\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015380859, step = 291300 (27.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67498\n",
            "INFO:tensorflow:examples/sec: 940.794\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (352, 30)\n",
            "INFO:tensorflow:loss = 0.014770508, step = 291400 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.571\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015136719, step = 291500 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80279\n",
            "INFO:tensorflow:examples/sec: 973.515\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (354, 59)\n",
            "INFO:tensorflow:loss = 0.01550293, step = 291600 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80262\n",
            "INFO:tensorflow:examples/sec: 973.47\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014343262, step = 291700 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80296\n",
            "INFO:tensorflow:examples/sec: 973.558\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (356, 88)\n",
            "INFO:tensorflow:loss = 0.016235352, step = 291800 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80288\n",
            "INFO:tensorflow:examples/sec: 973.537\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 291800...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 291800 into gs://bucket_comment_completion/Matteo/HP_TUNING/constant/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 291800...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014526367, step = 291900 (35.598 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.80914\n",
            "INFO:tensorflow:examples/sec: 719.14\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (358, 81)\n",
            "INFO:tensorflow:loss = 0.0138549805, step = 292000 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80284\n",
            "INFO:tensorflow:examples/sec: 973.527\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015258789, step = 292100 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.803\n",
            "INFO:tensorflow:examples/sec: 973.568\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014038086, step = 292200 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80284\n",
            "INFO:tensorflow:examples/sec: 973.528\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (361, 10)\n",
            "INFO:tensorflow:loss = 0.016357422, step = 292300 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80316\n",
            "INFO:tensorflow:examples/sec: 973.609\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016113281, step = 292400 (27.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66926\n",
            "INFO:tensorflow:examples/sec: 939.331\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (363, 35)\n",
            "INFO:tensorflow:loss = 0.014160156, step = 292500 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80277\n",
            "INFO:tensorflow:examples/sec: 973.51\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.013305664, step = 292600 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80263\n",
            "INFO:tensorflow:examples/sec: 973.474\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (365, 64)\n",
            "INFO:tensorflow:loss = 0.01574707, step = 292700 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80301\n",
            "INFO:tensorflow:examples/sec: 973.572\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014953613, step = 292800 (27.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66329\n",
            "INFO:tensorflow:examples/sec: 937.803\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (367, 89)\n",
            "INFO:tensorflow:loss = 0.017578125, step = 292900 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80291\n",
            "INFO:tensorflow:examples/sec: 973.546\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01586914, step = 293000 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.54\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014892578, step = 293100 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80295\n",
            "INFO:tensorflow:examples/sec: 973.556\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (370, 18)\n",
            "INFO:tensorflow:loss = 0.014526367, step = 293200 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80261\n",
            "INFO:tensorflow:examples/sec: 973.467\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016113281, step = 293300 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80266\n",
            "INFO:tensorflow:examples/sec: 973.482\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (372, 43)\n",
            "INFO:tensorflow:loss = 0.016845703, step = 293400 (27.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.65757\n",
            "INFO:tensorflow:examples/sec: 936.338\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015625, step = 293500 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80291\n",
            "INFO:tensorflow:examples/sec: 973.544\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (374, 72)\n",
            "INFO:tensorflow:loss = 0.016845703, step = 293600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80298\n",
            "INFO:tensorflow:examples/sec: 973.564\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016967773, step = 293700 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80296\n",
            "INFO:tensorflow:examples/sec: 973.558\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016845703, step = 293800 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.54\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (377, 0)\n",
            "INFO:tensorflow:loss = 0.013305664, step = 293900 (27.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.675\n",
            "INFO:tensorflow:examples/sec: 940.8\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015136719, step = 294000 (26.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80259\n",
            "INFO:tensorflow:examples/sec: 973.462\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (379, 29)\n",
            "INFO:tensorflow:loss = 0.014709473, step = 294100 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80315\n",
            "INFO:tensorflow:examples/sec: 973.606\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 294200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80293\n",
            "INFO:tensorflow:examples/sec: 973.55\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (381, 58)\n",
            "INFO:tensorflow:loss = 0.01574707, step = 294300 (27.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.6732\n",
            "INFO:tensorflow:examples/sec: 940.34\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.017822266, step = 294400 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80313\n",
            "INFO:tensorflow:examples/sec: 973.6\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (383, 83)\n",
            "INFO:tensorflow:loss = 0.014892578, step = 294500 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80299\n",
            "INFO:tensorflow:examples/sec: 973.566\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015319824, step = 294600 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8028\n",
            "INFO:tensorflow:examples/sec: 973.517\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016479492, step = 294700 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80303\n",
            "INFO:tensorflow:examples/sec: 973.575\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (386, 12)\n",
            "INFO:tensorflow:loss = 0.016113281, step = 294800 (26.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80247\n",
            "INFO:tensorflow:examples/sec: 973.431\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014709473, step = 294900 (27.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.655\n",
            "INFO:tensorflow:examples/sec: 935.679\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (388, 37)\n",
            "INFO:tensorflow:loss = 0.016113281, step = 295000 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.8032\n",
            "INFO:tensorflow:examples/sec: 973.619\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014953613, step = 295100 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80321\n",
            "INFO:tensorflow:examples/sec: 973.621\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (390, 66)\n",
            "INFO:tensorflow:loss = 0.014770508, step = 295200 (26.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80311\n",
            "INFO:tensorflow:examples/sec: 973.596\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.015625, step = 295300 (26.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80321\n",
            "INFO:tensorflow:examples/sec: 973.621\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (392, 91)\n",
            "INFO:tensorflow:loss = 0.016113281, step = 295400 (27.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.6784\n",
            "INFO:tensorflow:examples/sec: 941.671\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016479492, step = 295500 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80289\n",
            "INFO:tensorflow:examples/sec: 973.539\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.01586914, step = 295600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80299\n",
            "INFO:tensorflow:examples/sec: 973.565\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (395, 20)\n",
            "INFO:tensorflow:loss = 0.014404297, step = 295700 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80292\n",
            "INFO:tensorflow:examples/sec: 973.548\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014526367, step = 295800 (28.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.5426\n",
            "INFO:tensorflow:examples/sec: 906.906\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (397, 41)\n",
            "INFO:tensorflow:loss = 0.01373291, step = 295900 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80306\n",
            "INFO:tensorflow:examples/sec: 973.584\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014465332, step = 296000 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80292\n",
            "INFO:tensorflow:examples/sec: 973.549\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (399, 70)\n",
            "INFO:tensorflow:loss = 0.013916016, step = 296100 (26.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80277\n",
            "INFO:tensorflow:examples/sec: 973.509\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014282227, step = 296200 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80297\n",
            "INFO:tensorflow:examples/sec: 973.56\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (401, 99)\n",
            "INFO:tensorflow:loss = 0.012634277, step = 296300 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80286\n",
            "INFO:tensorflow:examples/sec: 973.533\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014282227, step = 296400 (27.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.67587\n",
            "INFO:tensorflow:examples/sec: 941.021\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.016601562, step = 296500 (26.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.80297\n",
            "INFO:tensorflow:examples/sec: 973.56\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (404, 24)\n",
            "INFO:tensorflow:loss = 0.016113281, step = 296600 (26.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.803\n",
            "INFO:tensorflow:examples/sec: 973.569\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.014038086, step = 296700 (26.297 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Onovg_IkJsxe"
      },
      "source": [
        "### Evaluate the performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBXTPr0ke04I"
      },
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = 512\n",
        "model.eval(\n",
        "    mixture_or_task_name=\"all_tasks\",\n",
        "    # mixture_or_task_name=\"all_tasks\",\n",
        "    checkpoint_steps=-1 #evaluate only last checkpoint\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}